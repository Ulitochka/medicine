2019-01-13 14:13:51,712 ****************************************************************************************************
2019-01-13 14:13:52,232 {'analyzer': 'word', 'max_features': None, 'binary': False, 'input': 'content', 'encoding': 'utf-8', 'ngram_range': (1, 5), 'strip_accents': None, 'max_df': 1.0, 'stop_words': {'ты', 'иногда', 'для', 'надо', 'чтобы', 'другой', 'того', 'мы', 'опять', 'всех', 'не', 'какой', 'нее', 'какая', 'до', 'будет', 'на', 'над', 'этом', 'почти', 'можно', 'тогда', 'потому', 'чем', 'тебя', 'ведь', 'уж', 'ней', 'ее', 'тоже', 'с', 'если', 'том', 'впрочем', 'я', 'ничего', 'был', 'ж', 'этот', 'потом', 'нет', 'себя', 'об', 'их', 'разве', 'по', 'ни', 'кто', 'этого', 'при', 'от', 'эту', 'всего', 'вы', 'теперь', 'да', 'перед', 'нас', 'может', 'сам', 'там', 'ну', 'чего', 'нельзя', 'всегда', 'у', 'о', 'из', 'тот', 'чтоб', 'и', 'было', 'только', 'за', 'вам', 'им', 'или', 'но', 'были', 'ли', 'так', 'более', 'меня', 'даже', 'а', 'все', 'моя', 'два', 'без', 'один', 'него', 'вот', 'ему', 'хоть', 'три', 'здесь', 'совсем', 'вдруг', 'всю', 'хорошо', 'будто', 'через', 'он', 'к', 'нибудь', 'когда', 'где', 'раз', 'них', 'никогда', 'такой', 'вас', 'они', 'как', 'между', 'то', 'тут', 'под', 'эти', 'ним', 'была', 'после', 'куда', 'еще', 'мне', 'много', 'она', 'этой', 'во', 'тем', 'конечно', 'что', 'лучше', 'быть', 'себе', 'больше', 'же', 'про', 'есть', 'сейчас', 'уже', 'свою', 'ей', 'бы', 'мой', 'его', 'со', 'чуть', 'зачем', 'наконец', 'в'}, 'tokenizer': None, 'dtype': <class 'numpy.int64'>, 'vocabulary': None, 'lowercase': True, 'token_pattern': '(?u)\\b\\w\\w+\\b', 'preprocessor': None, 'min_df': 1, 'decode_error': 'strict'}
2019-01-13 14:13:52,233 {'analyzer': 'word', 'sublinear_tf': False, 'max_features': None, 'binary': False, 'input': 'content', 'encoding': 'utf-8', 'smooth_idf': True, 'ngram_range': (1, 5), 'strip_accents': None, 'norm': 'l2', 'max_df': 1.0, 'stop_words': None, 'tokenizer': None, 'dtype': <class 'numpy.float64'>, 'vocabulary': None, 'lowercase': True, 'token_pattern': '(?u)\\b\\w\\w+\\b', 'preprocessor': None, 'use_idf': True, 'min_df': 1, 'decode_error': 'strict'}
2019-01-13 14:13:52,279 X_train features: (401, 68466);
2019-01-13 14:13:52,280 sympt_train_labels: (401, 92)
2019-01-13 14:13:52,280 X_test features: (45, 68466);
2019-01-13 14:13:52,280 sympt_test_labels: (45, 92)
2019-01-13 14:13:52,280 {'estimator__n_estimators': 82, 'estimator__learning_rate': 0.6191102982996944, 'estimator__criterion': 'friedman_mse', 'estimator__min_weight_fraction_leaf': 0.0, 'estimator__max_depth': 3, 'estimator__max_leaf_nodes': None, 'estimator__subsample': 1.0, 'estimator__warm_start': False, 'estimator__n_iter_no_change': None, 'estimator__min_impurity_split': None, 'n_jobs': -1, 'estimator__max_features': None, 'estimator__validation_fraction': 0.1, 'estimator__min_impurity_decrease': 0.0, 'estimator__random_state': 1024, 'estimator': GradientBoostingClassifier(criterion='friedman_mse', init=None,
              learning_rate=0.6191102982996944, loss='deviance',
              max_depth=3, max_features=None, max_leaf_nodes=None,
              min_impurity_decrease=0.0, min_impurity_split=None,
              min_samples_leaf=1, min_samples_split=2,
              min_weight_fraction_leaf=0.0, n_estimators=82,
              n_iter_no_change=None, presort='auto', random_state=1024,
              subsample=1.0, tol=0.0001, validation_fraction=0.1,
              verbose=1, warm_start=False), 'estimator__presort': 'auto', 'estimator__loss': 'deviance', 'estimator__min_samples_split': 2, 'estimator__init': None, 'estimator__tol': 0.0001, 'estimator__min_samples_leaf': 1, 'estimator__verbose': 1}
2019-01-13 14:14:37,233 ****************************************************************************************************
2019-01-13 14:14:37,751 {'analyzer': 'word', 'max_features': None, 'binary': False, 'input': 'content', 'encoding': 'utf-8', 'ngram_range': (1, 5), 'strip_accents': None, 'max_df': 1.0, 'stop_words': {'ты', 'иногда', 'для', 'надо', 'чтобы', 'другой', 'того', 'мы', 'опять', 'всех', 'не', 'какой', 'нее', 'какая', 'до', 'будет', 'на', 'над', 'этом', 'почти', 'можно', 'тогда', 'потому', 'чем', 'тебя', 'ведь', 'уж', 'ней', 'ее', 'тоже', 'с', 'если', 'том', 'впрочем', 'я', 'ничего', 'был', 'ж', 'этот', 'потом', 'нет', 'себя', 'об', 'их', 'разве', 'по', 'ни', 'кто', 'этого', 'при', 'от', 'эту', 'всего', 'вы', 'теперь', 'да', 'перед', 'нас', 'может', 'сам', 'там', 'ну', 'чего', 'нельзя', 'всегда', 'у', 'о', 'из', 'тот', 'чтоб', 'и', 'было', 'только', 'за', 'вам', 'им', 'или', 'но', 'были', 'ли', 'так', 'более', 'меня', 'даже', 'а', 'все', 'моя', 'два', 'без', 'один', 'него', 'вот', 'ему', 'хоть', 'три', 'здесь', 'совсем', 'вдруг', 'всю', 'хорошо', 'будто', 'через', 'он', 'к', 'нибудь', 'когда', 'где', 'раз', 'них', 'никогда', 'такой', 'вас', 'они', 'как', 'между', 'то', 'тут', 'под', 'эти', 'ним', 'была', 'после', 'куда', 'еще', 'мне', 'много', 'она', 'этой', 'во', 'тем', 'конечно', 'что', 'лучше', 'быть', 'себе', 'больше', 'же', 'про', 'есть', 'сейчас', 'уже', 'свою', 'ей', 'бы', 'мой', 'его', 'со', 'чуть', 'зачем', 'наконец', 'в'}, 'tokenizer': None, 'dtype': <class 'numpy.int64'>, 'vocabulary': None, 'lowercase': True, 'token_pattern': '(?u)\\b\\w\\w+\\b', 'preprocessor': None, 'min_df': 1, 'decode_error': 'strict'}
2019-01-13 14:14:37,752 {'analyzer': 'word', 'sublinear_tf': False, 'max_features': None, 'binary': False, 'input': 'content', 'encoding': 'utf-8', 'smooth_idf': True, 'ngram_range': (1, 5), 'strip_accents': None, 'norm': 'l2', 'max_df': 1.0, 'stop_words': None, 'tokenizer': None, 'dtype': <class 'numpy.float64'>, 'vocabulary': None, 'lowercase': True, 'token_pattern': '(?u)\\b\\w\\w+\\b', 'preprocessor': None, 'use_idf': True, 'min_df': 1, 'decode_error': 'strict'}
2019-01-13 14:14:37,801 X_train features: (401, 68466);
2019-01-13 14:14:37,802 sympt_train_labels: (401, 92)
2019-01-13 14:14:37,802 X_test features: (45, 68466);
2019-01-13 14:14:37,802 sympt_test_labels: (45, 92)
2019-01-13 14:14:37,802 {'estimator__n_estimators': 76, 'estimator__learning_rate': 0.5428631012213041, 'estimator__criterion': 'friedman_mse', 'estimator__min_weight_fraction_leaf': 0.0, 'estimator__max_depth': 3, 'estimator__max_leaf_nodes': None, 'estimator__subsample': 1.0, 'estimator__warm_start': False, 'estimator__n_iter_no_change': None, 'estimator__min_impurity_split': None, 'n_jobs': -1, 'estimator__max_features': None, 'estimator__validation_fraction': 0.1, 'estimator__min_impurity_decrease': 0.0, 'estimator__random_state': 1024, 'estimator': GradientBoostingClassifier(criterion='friedman_mse', init=None,
              learning_rate=0.5428631012213041, loss='deviance',
              max_depth=3, max_features=None, max_leaf_nodes=None,
              min_impurity_decrease=0.0, min_impurity_split=None,
              min_samples_leaf=1, min_samples_split=2,
              min_weight_fraction_leaf=0.0, n_estimators=76,
              n_iter_no_change=None, presort='auto', random_state=1024,
              subsample=1.0, tol=0.0001, validation_fraction=0.1,
              verbose=1, warm_start=False), 'estimator__presort': 'auto', 'estimator__loss': 'deviance', 'estimator__min_samples_split': 2, 'estimator__init': None, 'estimator__tol': 0.0001, 'estimator__min_samples_leaf': 1, 'estimator__verbose': 1}
2019-01-13 14:15:20,331 ****************************************************************************************************
2019-01-13 14:15:20,852 {'analyzer': 'word', 'max_features': None, 'binary': False, 'input': 'content', 'encoding': 'utf-8', 'ngram_range': (1, 5), 'strip_accents': None, 'max_df': 1.0, 'stop_words': {'ты', 'иногда', 'для', 'надо', 'чтобы', 'другой', 'того', 'мы', 'опять', 'всех', 'не', 'какой', 'нее', 'какая', 'до', 'будет', 'на', 'над', 'этом', 'почти', 'можно', 'тогда', 'потому', 'чем', 'тебя', 'ведь', 'уж', 'ней', 'ее', 'тоже', 'с', 'если', 'том', 'впрочем', 'я', 'ничего', 'был', 'ж', 'этот', 'потом', 'нет', 'себя', 'об', 'их', 'разве', 'по', 'ни', 'кто', 'этого', 'при', 'от', 'эту', 'всего', 'вы', 'теперь', 'да', 'перед', 'нас', 'может', 'сам', 'там', 'ну', 'чего', 'нельзя', 'всегда', 'у', 'о', 'из', 'тот', 'чтоб', 'и', 'было', 'только', 'за', 'вам', 'им', 'или', 'но', 'были', 'ли', 'так', 'более', 'меня', 'даже', 'а', 'все', 'моя', 'два', 'без', 'один', 'него', 'вот', 'ему', 'хоть', 'три', 'здесь', 'совсем', 'вдруг', 'всю', 'хорошо', 'будто', 'через', 'он', 'к', 'нибудь', 'когда', 'где', 'раз', 'них', 'никогда', 'такой', 'вас', 'они', 'как', 'между', 'то', 'тут', 'под', 'эти', 'ним', 'была', 'после', 'куда', 'еще', 'мне', 'много', 'она', 'этой', 'во', 'тем', 'конечно', 'что', 'лучше', 'быть', 'себе', 'больше', 'же', 'про', 'есть', 'сейчас', 'уже', 'свою', 'ей', 'бы', 'мой', 'его', 'со', 'чуть', 'зачем', 'наконец', 'в'}, 'tokenizer': None, 'dtype': <class 'numpy.int64'>, 'vocabulary': None, 'lowercase': True, 'token_pattern': '(?u)\\b\\w\\w+\\b', 'preprocessor': None, 'min_df': 1, 'decode_error': 'strict'}
2019-01-13 14:15:20,852 {'analyzer': 'word', 'sublinear_tf': False, 'max_features': None, 'binary': False, 'input': 'content', 'encoding': 'utf-8', 'smooth_idf': True, 'ngram_range': (1, 5), 'strip_accents': None, 'norm': 'l2', 'max_df': 1.0, 'stop_words': None, 'tokenizer': None, 'dtype': <class 'numpy.float64'>, 'vocabulary': None, 'lowercase': True, 'token_pattern': '(?u)\\b\\w\\w+\\b', 'preprocessor': None, 'use_idf': True, 'min_df': 1, 'decode_error': 'strict'}
2019-01-13 14:15:20,900 X_train features: (401, 68466);
2019-01-13 14:15:20,900 sympt_train_labels: (401, 92)
2019-01-13 14:15:20,901 X_test features: (45, 68466);
2019-01-13 14:15:20,901 sympt_test_labels: (45, 92)
2019-01-13 14:15:20,901 {'estimator__n_estimators': 99, 'estimator__learning_rate': 0.6653066691288793, 'estimator__criterion': 'friedman_mse', 'estimator__min_weight_fraction_leaf': 0.0, 'estimator__max_depth': 3, 'estimator__max_leaf_nodes': None, 'estimator__subsample': 1.0, 'estimator__warm_start': False, 'estimator__n_iter_no_change': None, 'estimator__min_impurity_split': None, 'n_jobs': -1, 'estimator__max_features': None, 'estimator__validation_fraction': 0.1, 'estimator__min_impurity_decrease': 0.0, 'estimator__random_state': 1024, 'estimator': GradientBoostingClassifier(criterion='friedman_mse', init=None,
              learning_rate=0.6653066691288793, loss='deviance',
              max_depth=3, max_features=None, max_leaf_nodes=None,
              min_impurity_decrease=0.0, min_impurity_split=None,
              min_samples_leaf=1, min_samples_split=2,
              min_weight_fraction_leaf=0.0, n_estimators=99,
              n_iter_no_change=None, presort='auto', random_state=1024,
              subsample=1.0, tol=0.0001, validation_fraction=0.1,
              verbose=1, warm_start=False), 'estimator__presort': 'auto', 'estimator__loss': 'deviance', 'estimator__min_samples_split': 2, 'estimator__init': None, 'estimator__tol': 0.0001, 'estimator__min_samples_leaf': 1, 'estimator__verbose': 1}
2019-01-13 14:16:00,770 ****************************************************************************************************
2019-01-13 14:16:01,254 {'analyzer': 'word', 'max_features': None, 'binary': False, 'input': 'content', 'encoding': 'utf-8', 'ngram_range': (1, 5), 'strip_accents': None, 'max_df': 1.0, 'stop_words': {'ты', 'иногда', 'для', 'надо', 'чтобы', 'другой', 'того', 'мы', 'опять', 'всех', 'не', 'какой', 'нее', 'какая', 'до', 'будет', 'на', 'над', 'этом', 'почти', 'можно', 'тогда', 'потому', 'чем', 'тебя', 'ведь', 'уж', 'ней', 'ее', 'тоже', 'с', 'если', 'том', 'впрочем', 'я', 'ничего', 'был', 'ж', 'этот', 'потом', 'нет', 'себя', 'об', 'их', 'разве', 'по', 'ни', 'кто', 'этого', 'при', 'от', 'эту', 'всего', 'вы', 'теперь', 'да', 'перед', 'нас', 'может', 'сам', 'там', 'ну', 'чего', 'нельзя', 'всегда', 'у', 'о', 'из', 'тот', 'чтоб', 'и', 'было', 'только', 'за', 'вам', 'им', 'или', 'но', 'были', 'ли', 'так', 'более', 'меня', 'даже', 'а', 'все', 'моя', 'два', 'без', 'один', 'него', 'вот', 'ему', 'хоть', 'три', 'здесь', 'совсем', 'вдруг', 'всю', 'хорошо', 'будто', 'через', 'он', 'к', 'нибудь', 'когда', 'где', 'раз', 'них', 'никогда', 'такой', 'вас', 'они', 'как', 'между', 'то', 'тут', 'под', 'эти', 'ним', 'была', 'после', 'куда', 'еще', 'мне', 'много', 'она', 'этой', 'во', 'тем', 'конечно', 'что', 'лучше', 'быть', 'себе', 'больше', 'же', 'про', 'есть', 'сейчас', 'уже', 'свою', 'ей', 'бы', 'мой', 'его', 'со', 'чуть', 'зачем', 'наконец', 'в'}, 'tokenizer': None, 'dtype': <class 'numpy.int64'>, 'vocabulary': None, 'lowercase': True, 'token_pattern': '(?u)\\b\\w\\w+\\b', 'preprocessor': None, 'min_df': 1, 'decode_error': 'strict'}
2019-01-13 14:16:01,255 {'analyzer': 'word', 'sublinear_tf': False, 'max_features': None, 'binary': False, 'input': 'content', 'encoding': 'utf-8', 'smooth_idf': True, 'ngram_range': (1, 5), 'strip_accents': None, 'norm': 'l2', 'max_df': 1.0, 'stop_words': None, 'tokenizer': None, 'dtype': <class 'numpy.float64'>, 'vocabulary': None, 'lowercase': True, 'token_pattern': '(?u)\\b\\w\\w+\\b', 'preprocessor': None, 'use_idf': True, 'min_df': 1, 'decode_error': 'strict'}
2019-01-13 14:16:01,301 X_train features: (401, 68466);
2019-01-13 14:16:01,301 sympt_train_labels: (401, 92)
2019-01-13 14:16:01,301 X_test features: (45, 68466);
2019-01-13 14:16:01,301 sympt_test_labels: (45, 92)
2019-01-13 14:16:01,301 {'estimator__n_estimators': 59, 'estimator__learning_rate': 0.05, 'estimator__criterion': 'friedman_mse', 'estimator__min_weight_fraction_leaf': 0.0, 'estimator__max_depth': 3, 'estimator__max_leaf_nodes': None, 'estimator__subsample': 1.0, 'estimator__warm_start': False, 'estimator__n_iter_no_change': None, 'estimator__min_impurity_split': None, 'n_jobs': -1, 'estimator__max_features': None, 'estimator__validation_fraction': 0.1, 'estimator__min_impurity_decrease': 0.0, 'estimator__random_state': 1024, 'estimator': GradientBoostingClassifier(criterion='friedman_mse', init=None,
              learning_rate=0.05, loss='deviance', max_depth=3,
              max_features=None, max_leaf_nodes=None,
              min_impurity_decrease=0.0, min_impurity_split=None,
              min_samples_leaf=1, min_samples_split=2,
              min_weight_fraction_leaf=0.0, n_estimators=59,
              n_iter_no_change=None, presort='auto', random_state=1024,
              subsample=1.0, tol=0.0001, validation_fraction=0.1,
              verbose=1, warm_start=False), 'estimator__presort': 'auto', 'estimator__loss': 'deviance', 'estimator__min_samples_split': 2, 'estimator__init': None, 'estimator__tol': 0.0001, 'estimator__min_samples_leaf': 1, 'estimator__verbose': 1}
2019-01-13 14:20:19,507 ****************************************************************************************************
2019-01-13 14:20:20,072 {'analyzer': 'word', 'max_features': None, 'binary': False, 'input': 'content', 'encoding': 'utf-8', 'ngram_range': (1, 5), 'strip_accents': None, 'max_df': 1.0, 'stop_words': {'ты', 'иногда', 'для', 'надо', 'чтобы', 'другой', 'того', 'мы', 'опять', 'всех', 'не', 'какой', 'нее', 'какая', 'до', 'будет', 'на', 'над', 'этом', 'почти', 'можно', 'тогда', 'потому', 'чем', 'тебя', 'ведь', 'уж', 'ней', 'ее', 'тоже', 'с', 'если', 'том', 'впрочем', 'я', 'ничего', 'был', 'ж', 'этот', 'потом', 'нет', 'себя', 'об', 'их', 'разве', 'по', 'ни', 'кто', 'этого', 'при', 'от', 'эту', 'всего', 'вы', 'теперь', 'да', 'перед', 'нас', 'может', 'сам', 'там', 'ну', 'чего', 'нельзя', 'всегда', 'у', 'о', 'из', 'тот', 'чтоб', 'и', 'было', 'только', 'за', 'вам', 'им', 'или', 'но', 'были', 'ли', 'так', 'более', 'меня', 'даже', 'а', 'все', 'моя', 'два', 'без', 'один', 'него', 'вот', 'ему', 'хоть', 'три', 'здесь', 'совсем', 'вдруг', 'всю', 'хорошо', 'будто', 'через', 'он', 'к', 'нибудь', 'когда', 'где', 'раз', 'них', 'никогда', 'такой', 'вас', 'они', 'как', 'между', 'то', 'тут', 'под', 'эти', 'ним', 'была', 'после', 'куда', 'еще', 'мне', 'много', 'она', 'этой', 'во', 'тем', 'конечно', 'что', 'лучше', 'быть', 'себе', 'больше', 'же', 'про', 'есть', 'сейчас', 'уже', 'свою', 'ей', 'бы', 'мой', 'его', 'со', 'чуть', 'зачем', 'наконец', 'в'}, 'tokenizer': None, 'dtype': <class 'numpy.int64'>, 'vocabulary': None, 'lowercase': True, 'token_pattern': '(?u)\\b\\w\\w+\\b', 'preprocessor': None, 'min_df': 1, 'decode_error': 'strict'}
2019-01-13 14:20:20,072 {'analyzer': 'word', 'sublinear_tf': False, 'max_features': None, 'binary': False, 'input': 'content', 'encoding': 'utf-8', 'smooth_idf': True, 'ngram_range': (1, 5), 'strip_accents': None, 'norm': 'l2', 'max_df': 1.0, 'stop_words': None, 'tokenizer': None, 'dtype': <class 'numpy.float64'>, 'vocabulary': None, 'lowercase': True, 'token_pattern': '(?u)\\b\\w\\w+\\b', 'preprocessor': None, 'use_idf': True, 'min_df': 1, 'decode_error': 'strict'}
2019-01-13 14:20:20,120 X_train features: (401, 68466);
2019-01-13 14:20:20,120 sympt_train_labels: (401, 92)
2019-01-13 14:20:20,120 X_test features: (45, 68466);
2019-01-13 14:20:20,120 sympt_test_labels: (45, 92)
2019-01-13 14:20:20,121 {'estimator__n_estimators': 49, 'estimator__learning_rate': 1.0, 'estimator__criterion': 'friedman_mse', 'estimator__min_weight_fraction_leaf': 0.0, 'estimator__max_depth': 3, 'estimator__max_leaf_nodes': None, 'estimator__subsample': 1.0, 'estimator__warm_start': False, 'estimator__n_iter_no_change': None, 'estimator__min_impurity_split': None, 'n_jobs': -1, 'estimator__max_features': None, 'estimator__validation_fraction': 0.1, 'estimator__min_impurity_decrease': 0.0, 'estimator__random_state': 1024, 'estimator': GradientBoostingClassifier(criterion='friedman_mse', init=None,
              learning_rate=1.0, loss='deviance', max_depth=3,
              max_features=None, max_leaf_nodes=None,
              min_impurity_decrease=0.0, min_impurity_split=None,
              min_samples_leaf=1, min_samples_split=2,
              min_weight_fraction_leaf=0.0, n_estimators=49,
              n_iter_no_change=None, presort='auto', random_state=1024,
              subsample=1.0, tol=0.0001, validation_fraction=0.1,
              verbose=1, warm_start=False), 'estimator__presort': 'auto', 'estimator__loss': 'deviance', 'estimator__min_samples_split': 2, 'estimator__init': None, 'estimator__tol': 0.0001, 'estimator__min_samples_leaf': 1, 'estimator__verbose': 1}
2019-01-13 14:20:43,364 ****************************************************************************************************
2019-01-13 14:20:43,823 {'analyzer': 'word', 'max_features': None, 'binary': False, 'input': 'content', 'encoding': 'utf-8', 'ngram_range': (1, 5), 'strip_accents': None, 'max_df': 1.0, 'stop_words': {'ты', 'иногда', 'для', 'надо', 'чтобы', 'другой', 'того', 'мы', 'опять', 'всех', 'не', 'какой', 'нее', 'какая', 'до', 'будет', 'на', 'над', 'этом', 'почти', 'можно', 'тогда', 'потому', 'чем', 'тебя', 'ведь', 'уж', 'ней', 'ее', 'тоже', 'с', 'если', 'том', 'впрочем', 'я', 'ничего', 'был', 'ж', 'этот', 'потом', 'нет', 'себя', 'об', 'их', 'разве', 'по', 'ни', 'кто', 'этого', 'при', 'от', 'эту', 'всего', 'вы', 'теперь', 'да', 'перед', 'нас', 'может', 'сам', 'там', 'ну', 'чего', 'нельзя', 'всегда', 'у', 'о', 'из', 'тот', 'чтоб', 'и', 'было', 'только', 'за', 'вам', 'им', 'или', 'но', 'были', 'ли', 'так', 'более', 'меня', 'даже', 'а', 'все', 'моя', 'два', 'без', 'один', 'него', 'вот', 'ему', 'хоть', 'три', 'здесь', 'совсем', 'вдруг', 'всю', 'хорошо', 'будто', 'через', 'он', 'к', 'нибудь', 'когда', 'где', 'раз', 'них', 'никогда', 'такой', 'вас', 'они', 'как', 'между', 'то', 'тут', 'под', 'эти', 'ним', 'была', 'после', 'куда', 'еще', 'мне', 'много', 'она', 'этой', 'во', 'тем', 'конечно', 'что', 'лучше', 'быть', 'себе', 'больше', 'же', 'про', 'есть', 'сейчас', 'уже', 'свою', 'ей', 'бы', 'мой', 'его', 'со', 'чуть', 'зачем', 'наконец', 'в'}, 'tokenizer': None, 'dtype': <class 'numpy.int64'>, 'vocabulary': None, 'lowercase': True, 'token_pattern': '(?u)\\b\\w\\w+\\b', 'preprocessor': None, 'min_df': 1, 'decode_error': 'strict'}
2019-01-13 14:20:43,823 {'analyzer': 'word', 'sublinear_tf': False, 'max_features': None, 'binary': False, 'input': 'content', 'encoding': 'utf-8', 'smooth_idf': True, 'ngram_range': (1, 5), 'strip_accents': None, 'norm': 'l2', 'max_df': 1.0, 'stop_words': None, 'tokenizer': None, 'dtype': <class 'numpy.float64'>, 'vocabulary': None, 'lowercase': True, 'token_pattern': '(?u)\\b\\w\\w+\\b', 'preprocessor': None, 'use_idf': True, 'min_df': 1, 'decode_error': 'strict'}
2019-01-13 14:20:43,870 X_train features: (401, 68466);
2019-01-13 14:20:43,871 sympt_train_labels: (401, 92)
2019-01-13 14:20:43,871 X_test features: (45, 68466);
2019-01-13 14:20:43,871 sympt_test_labels: (45, 92)
2019-01-13 14:20:43,871 {'estimator__n_estimators': 82, 'estimator__learning_rate': 0.6191102982996944, 'estimator__criterion': 'friedman_mse', 'estimator__min_weight_fraction_leaf': 0.0, 'estimator__max_depth': 3, 'estimator__max_leaf_nodes': None, 'estimator__subsample': 1.0, 'estimator__warm_start': False, 'estimator__n_iter_no_change': None, 'estimator__min_impurity_split': None, 'n_jobs': -1, 'estimator__max_features': None, 'estimator__validation_fraction': 0.1, 'estimator__min_impurity_decrease': 0.0, 'estimator__random_state': 1024, 'estimator': GradientBoostingClassifier(criterion='friedman_mse', init=None,
              learning_rate=0.6191102982996944, loss='deviance',
              max_depth=3, max_features=None, max_leaf_nodes=None,
              min_impurity_decrease=0.0, min_impurity_split=None,
              min_samples_leaf=1, min_samples_split=2,
              min_weight_fraction_leaf=0.0, n_estimators=82,
              n_iter_no_change=None, presort='auto', random_state=1024,
              subsample=1.0, tol=0.0001, validation_fraction=0.1,
              verbose=1, warm_start=False), 'estimator__presort': 'auto', 'estimator__loss': 'deviance', 'estimator__min_samples_split': 2, 'estimator__init': None, 'estimator__tol': 0.0001, 'estimator__min_samples_leaf': 1, 'estimator__verbose': 1}
2019-01-13 14:21:25,387 ****************************************************************************************************
2019-01-13 14:21:25,860 {'analyzer': 'word', 'max_features': None, 'binary': False, 'input': 'content', 'encoding': 'utf-8', 'ngram_range': (1, 5), 'strip_accents': None, 'max_df': 1.0, 'stop_words': {'ты', 'иногда', 'для', 'надо', 'чтобы', 'другой', 'того', 'мы', 'опять', 'всех', 'не', 'какой', 'нее', 'какая', 'до', 'будет', 'на', 'над', 'этом', 'почти', 'можно', 'тогда', 'потому', 'чем', 'тебя', 'ведь', 'уж', 'ней', 'ее', 'тоже', 'с', 'если', 'том', 'впрочем', 'я', 'ничего', 'был', 'ж', 'этот', 'потом', 'нет', 'себя', 'об', 'их', 'разве', 'по', 'ни', 'кто', 'этого', 'при', 'от', 'эту', 'всего', 'вы', 'теперь', 'да', 'перед', 'нас', 'может', 'сам', 'там', 'ну', 'чего', 'нельзя', 'всегда', 'у', 'о', 'из', 'тот', 'чтоб', 'и', 'было', 'только', 'за', 'вам', 'им', 'или', 'но', 'были', 'ли', 'так', 'более', 'меня', 'даже', 'а', 'все', 'моя', 'два', 'без', 'один', 'него', 'вот', 'ему', 'хоть', 'три', 'здесь', 'совсем', 'вдруг', 'всю', 'хорошо', 'будто', 'через', 'он', 'к', 'нибудь', 'когда', 'где', 'раз', 'них', 'никогда', 'такой', 'вас', 'они', 'как', 'между', 'то', 'тут', 'под', 'эти', 'ним', 'была', 'после', 'куда', 'еще', 'мне', 'много', 'она', 'этой', 'во', 'тем', 'конечно', 'что', 'лучше', 'быть', 'себе', 'больше', 'же', 'про', 'есть', 'сейчас', 'уже', 'свою', 'ей', 'бы', 'мой', 'его', 'со', 'чуть', 'зачем', 'наконец', 'в'}, 'tokenizer': None, 'dtype': <class 'numpy.int64'>, 'vocabulary': None, 'lowercase': True, 'token_pattern': '(?u)\\b\\w\\w+\\b', 'preprocessor': None, 'min_df': 1, 'decode_error': 'strict'}
2019-01-13 14:21:25,865 {'analyzer': 'word', 'sublinear_tf': False, 'max_features': None, 'binary': False, 'input': 'content', 'encoding': 'utf-8', 'smooth_idf': True, 'ngram_range': (1, 5), 'strip_accents': None, 'norm': 'l2', 'max_df': 1.0, 'stop_words': None, 'tokenizer': None, 'dtype': <class 'numpy.float64'>, 'vocabulary': None, 'lowercase': True, 'token_pattern': '(?u)\\b\\w\\w+\\b', 'preprocessor': None, 'use_idf': True, 'min_df': 1, 'decode_error': 'strict'}
2019-01-13 14:21:25,913 X_train features: (402, 68466);
2019-01-13 14:21:25,913 sympt_train_labels: (402, 92)
2019-01-13 14:21:25,913 X_test features: (44, 68466);
2019-01-13 14:21:25,913 sympt_test_labels: (44, 92)
2019-01-13 14:21:25,914 {'estimator__n_estimators': 82, 'estimator__learning_rate': 0.6191102982996944, 'estimator__criterion': 'friedman_mse', 'estimator__min_weight_fraction_leaf': 0.0, 'estimator__max_depth': 3, 'estimator__max_leaf_nodes': None, 'estimator__subsample': 1.0, 'estimator__warm_start': False, 'estimator__n_iter_no_change': None, 'estimator__min_impurity_split': None, 'n_jobs': -1, 'estimator__max_features': None, 'estimator__validation_fraction': 0.1, 'estimator__min_impurity_decrease': 0.0, 'estimator__random_state': 1024, 'estimator': GradientBoostingClassifier(criterion='friedman_mse', init=None,
              learning_rate=0.6191102982996944, loss='deviance',
              max_depth=3, max_features=None, max_leaf_nodes=None,
              min_impurity_decrease=0.0, min_impurity_split=None,
              min_samples_leaf=1, min_samples_split=2,
              min_weight_fraction_leaf=0.0, n_estimators=82,
              n_iter_no_change=None, presort='auto', random_state=1024,
              subsample=1.0, tol=0.0001, validation_fraction=0.1,
              verbose=1, warm_start=False), 'estimator__presort': 'auto', 'estimator__loss': 'deviance', 'estimator__min_samples_split': 2, 'estimator__init': None, 'estimator__tol': 0.0001, 'estimator__min_samples_leaf': 1, 'estimator__verbose': 1}
2019-01-13 14:22:01,731 ****************************************************************************************************
2019-01-13 14:22:02,221 {'analyzer': 'word', 'max_features': None, 'binary': False, 'input': 'content', 'encoding': 'utf-8', 'ngram_range': (1, 5), 'strip_accents': None, 'max_df': 1.0, 'stop_words': {'ты', 'иногда', 'для', 'надо', 'чтобы', 'другой', 'того', 'мы', 'опять', 'всех', 'не', 'какой', 'нее', 'какая', 'до', 'будет', 'на', 'над', 'этом', 'почти', 'можно', 'тогда', 'потому', 'чем', 'тебя', 'ведь', 'уж', 'ней', 'ее', 'тоже', 'с', 'если', 'том', 'впрочем', 'я', 'ничего', 'был', 'ж', 'этот', 'потом', 'нет', 'себя', 'об', 'их', 'разве', 'по', 'ни', 'кто', 'этого', 'при', 'от', 'эту', 'всего', 'вы', 'теперь', 'да', 'перед', 'нас', 'может', 'сам', 'там', 'ну', 'чего', 'нельзя', 'всегда', 'у', 'о', 'из', 'тот', 'чтоб', 'и', 'было', 'только', 'за', 'вам', 'им', 'или', 'но', 'были', 'ли', 'так', 'более', 'меня', 'даже', 'а', 'все', 'моя', 'два', 'без', 'один', 'него', 'вот', 'ему', 'хоть', 'три', 'здесь', 'совсем', 'вдруг', 'всю', 'хорошо', 'будто', 'через', 'он', 'к', 'нибудь', 'когда', 'где', 'раз', 'них', 'никогда', 'такой', 'вас', 'они', 'как', 'между', 'то', 'тут', 'под', 'эти', 'ним', 'была', 'после', 'куда', 'еще', 'мне', 'много', 'она', 'этой', 'во', 'тем', 'конечно', 'что', 'лучше', 'быть', 'себе', 'больше', 'же', 'про', 'есть', 'сейчас', 'уже', 'свою', 'ей', 'бы', 'мой', 'его', 'со', 'чуть', 'зачем', 'наконец', 'в'}, 'tokenizer': None, 'dtype': <class 'numpy.int64'>, 'vocabulary': None, 'lowercase': True, 'token_pattern': '(?u)\\b\\w\\w+\\b', 'preprocessor': None, 'min_df': 1, 'decode_error': 'strict'}
2019-01-13 14:22:02,221 {'analyzer': 'word', 'sublinear_tf': False, 'max_features': None, 'binary': False, 'input': 'content', 'encoding': 'utf-8', 'smooth_idf': True, 'ngram_range': (1, 5), 'strip_accents': None, 'norm': 'l2', 'max_df': 1.0, 'stop_words': None, 'tokenizer': None, 'dtype': <class 'numpy.float64'>, 'vocabulary': None, 'lowercase': True, 'token_pattern': '(?u)\\b\\w\\w+\\b', 'preprocessor': None, 'use_idf': True, 'min_df': 1, 'decode_error': 'strict'}
2019-01-13 14:22:02,268 X_train features: (402, 68466);
2019-01-13 14:22:02,268 sympt_train_labels: (402, 92)
2019-01-13 14:22:02,268 X_test features: (44, 68466);
2019-01-13 14:22:02,268 sympt_test_labels: (44, 92)
2019-01-13 14:22:02,268 {'estimator__n_estimators': 99, 'estimator__learning_rate': 0.057476929447565744, 'estimator__criterion': 'friedman_mse', 'estimator__min_weight_fraction_leaf': 0.0, 'estimator__max_depth': 3, 'estimator__max_leaf_nodes': None, 'estimator__subsample': 1.0, 'estimator__warm_start': False, 'estimator__n_iter_no_change': None, 'estimator__min_impurity_split': None, 'n_jobs': -1, 'estimator__max_features': None, 'estimator__validation_fraction': 0.1, 'estimator__min_impurity_decrease': 0.0, 'estimator__random_state': 1024, 'estimator': GradientBoostingClassifier(criterion='friedman_mse', init=None,
              learning_rate=0.057476929447565744, loss='deviance',
              max_depth=3, max_features=None, max_leaf_nodes=None,
              min_impurity_decrease=0.0, min_impurity_split=None,
              min_samples_leaf=1, min_samples_split=2,
              min_weight_fraction_leaf=0.0, n_estimators=99,
              n_iter_no_change=None, presort='auto', random_state=1024,
              subsample=1.0, tol=0.0001, validation_fraction=0.1,
              verbose=1, warm_start=False), 'estimator__presort': 'auto', 'estimator__loss': 'deviance', 'estimator__min_samples_split': 2, 'estimator__init': None, 'estimator__tol': 0.0001, 'estimator__min_samples_leaf': 1, 'estimator__verbose': 1}
2019-01-13 14:28:40,238 ****************************************************************************************************
2019-01-13 14:28:40,749 {'analyzer': 'word', 'max_features': None, 'binary': False, 'input': 'content', 'encoding': 'utf-8', 'ngram_range': (1, 5), 'strip_accents': None, 'max_df': 1.0, 'stop_words': {'ты', 'иногда', 'для', 'надо', 'чтобы', 'другой', 'того', 'мы', 'опять', 'всех', 'не', 'какой', 'нее', 'какая', 'до', 'будет', 'на', 'над', 'этом', 'почти', 'можно', 'тогда', 'потому', 'чем', 'тебя', 'ведь', 'уж', 'ней', 'ее', 'тоже', 'с', 'если', 'том', 'впрочем', 'я', 'ничего', 'был', 'ж', 'этот', 'потом', 'нет', 'себя', 'об', 'их', 'разве', 'по', 'ни', 'кто', 'этого', 'при', 'от', 'эту', 'всего', 'вы', 'теперь', 'да', 'перед', 'нас', 'может', 'сам', 'там', 'ну', 'чего', 'нельзя', 'всегда', 'у', 'о', 'из', 'тот', 'чтоб', 'и', 'было', 'только', 'за', 'вам', 'им', 'или', 'но', 'были', 'ли', 'так', 'более', 'меня', 'даже', 'а', 'все', 'моя', 'два', 'без', 'один', 'него', 'вот', 'ему', 'хоть', 'три', 'здесь', 'совсем', 'вдруг', 'всю', 'хорошо', 'будто', 'через', 'он', 'к', 'нибудь', 'когда', 'где', 'раз', 'них', 'никогда', 'такой', 'вас', 'они', 'как', 'между', 'то', 'тут', 'под', 'эти', 'ним', 'была', 'после', 'куда', 'еще', 'мне', 'много', 'она', 'этой', 'во', 'тем', 'конечно', 'что', 'лучше', 'быть', 'себе', 'больше', 'же', 'про', 'есть', 'сейчас', 'уже', 'свою', 'ей', 'бы', 'мой', 'его', 'со', 'чуть', 'зачем', 'наконец', 'в'}, 'tokenizer': None, 'dtype': <class 'numpy.int64'>, 'vocabulary': None, 'lowercase': True, 'token_pattern': '(?u)\\b\\w\\w+\\b', 'preprocessor': None, 'min_df': 1, 'decode_error': 'strict'}
2019-01-13 14:28:40,749 {'analyzer': 'word', 'sublinear_tf': False, 'max_features': None, 'binary': False, 'input': 'content', 'encoding': 'utf-8', 'smooth_idf': True, 'ngram_range': (1, 5), 'strip_accents': None, 'norm': 'l2', 'max_df': 1.0, 'stop_words': None, 'tokenizer': None, 'dtype': <class 'numpy.float64'>, 'vocabulary': None, 'lowercase': True, 'token_pattern': '(?u)\\b\\w\\w+\\b', 'preprocessor': None, 'use_idf': True, 'min_df': 1, 'decode_error': 'strict'}
2019-01-13 14:28:40,794 X_train features: (402, 68466);
2019-01-13 14:28:40,795 sympt_train_labels: (402, 92)
2019-01-13 14:28:40,795 X_test features: (44, 68466);
2019-01-13 14:28:40,795 sympt_test_labels: (44, 92)
2019-01-13 14:28:40,795 {'estimator__n_estimators': 99, 'estimator__learning_rate': 0.6653066691288793, 'estimator__criterion': 'friedman_mse', 'estimator__min_weight_fraction_leaf': 0.0, 'estimator__max_depth': 3, 'estimator__max_leaf_nodes': None, 'estimator__subsample': 1.0, 'estimator__warm_start': False, 'estimator__n_iter_no_change': None, 'estimator__min_impurity_split': None, 'n_jobs': -1, 'estimator__max_features': None, 'estimator__validation_fraction': 0.1, 'estimator__min_impurity_decrease': 0.0, 'estimator__random_state': 1024, 'estimator': GradientBoostingClassifier(criterion='friedman_mse', init=None,
              learning_rate=0.6653066691288793, loss='deviance',
              max_depth=3, max_features=None, max_leaf_nodes=None,
              min_impurity_decrease=0.0, min_impurity_split=None,
              min_samples_leaf=1, min_samples_split=2,
              min_weight_fraction_leaf=0.0, n_estimators=99,
              n_iter_no_change=None, presort='auto', random_state=1024,
              subsample=1.0, tol=0.0001, validation_fraction=0.1,
              verbose=1, warm_start=False), 'estimator__presort': 'auto', 'estimator__loss': 'deviance', 'estimator__min_samples_split': 2, 'estimator__init': None, 'estimator__tol': 0.0001, 'estimator__min_samples_leaf': 1, 'estimator__verbose': 1}
2019-01-13 14:29:21,345 ****************************************************************************************************
2019-01-13 14:29:21,807 {'analyzer': 'word', 'max_features': None, 'binary': False, 'input': 'content', 'encoding': 'utf-8', 'ngram_range': (1, 5), 'strip_accents': None, 'max_df': 1.0, 'stop_words': {'ты', 'иногда', 'для', 'надо', 'чтобы', 'другой', 'того', 'мы', 'опять', 'всех', 'не', 'какой', 'нее', 'какая', 'до', 'будет', 'на', 'над', 'этом', 'почти', 'можно', 'тогда', 'потому', 'чем', 'тебя', 'ведь', 'уж', 'ней', 'ее', 'тоже', 'с', 'если', 'том', 'впрочем', 'я', 'ничего', 'был', 'ж', 'этот', 'потом', 'нет', 'себя', 'об', 'их', 'разве', 'по', 'ни', 'кто', 'этого', 'при', 'от', 'эту', 'всего', 'вы', 'теперь', 'да', 'перед', 'нас', 'может', 'сам', 'там', 'ну', 'чего', 'нельзя', 'всегда', 'у', 'о', 'из', 'тот', 'чтоб', 'и', 'было', 'только', 'за', 'вам', 'им', 'или', 'но', 'были', 'ли', 'так', 'более', 'меня', 'даже', 'а', 'все', 'моя', 'два', 'без', 'один', 'него', 'вот', 'ему', 'хоть', 'три', 'здесь', 'совсем', 'вдруг', 'всю', 'хорошо', 'будто', 'через', 'он', 'к', 'нибудь', 'когда', 'где', 'раз', 'них', 'никогда', 'такой', 'вас', 'они', 'как', 'между', 'то', 'тут', 'под', 'эти', 'ним', 'была', 'после', 'куда', 'еще', 'мне', 'много', 'она', 'этой', 'во', 'тем', 'конечно', 'что', 'лучше', 'быть', 'себе', 'больше', 'же', 'про', 'есть', 'сейчас', 'уже', 'свою', 'ей', 'бы', 'мой', 'его', 'со', 'чуть', 'зачем', 'наконец', 'в'}, 'tokenizer': None, 'dtype': <class 'numpy.int64'>, 'vocabulary': None, 'lowercase': True, 'token_pattern': '(?u)\\b\\w\\w+\\b', 'preprocessor': None, 'min_df': 1, 'decode_error': 'strict'}
2019-01-13 14:29:21,807 {'analyzer': 'word', 'sublinear_tf': False, 'max_features': None, 'binary': False, 'input': 'content', 'encoding': 'utf-8', 'smooth_idf': True, 'ngram_range': (1, 5), 'strip_accents': None, 'norm': 'l2', 'max_df': 1.0, 'stop_words': None, 'tokenizer': None, 'dtype': <class 'numpy.float64'>, 'vocabulary': None, 'lowercase': True, 'token_pattern': '(?u)\\b\\w\\w+\\b', 'preprocessor': None, 'use_idf': True, 'min_df': 1, 'decode_error': 'strict'}
2019-01-13 14:29:21,854 X_train features: (402, 68466);
2019-01-13 14:29:21,854 sympt_train_labels: (402, 92)
2019-01-13 14:29:21,854 X_test features: (44, 68466);
2019-01-13 14:29:21,854 sympt_test_labels: (44, 92)
2019-01-13 14:29:21,855 {'estimator__n_estimators': 82, 'estimator__learning_rate': 0.6191102982996944, 'estimator__criterion': 'friedman_mse', 'estimator__min_weight_fraction_leaf': 0.0, 'estimator__max_depth': 3, 'estimator__max_leaf_nodes': None, 'estimator__subsample': 1.0, 'estimator__warm_start': False, 'estimator__n_iter_no_change': None, 'estimator__min_impurity_split': None, 'n_jobs': -1, 'estimator__max_features': None, 'estimator__validation_fraction': 0.1, 'estimator__min_impurity_decrease': 0.0, 'estimator__random_state': 1024, 'estimator': GradientBoostingClassifier(criterion='friedman_mse', init=None,
              learning_rate=0.6191102982996944, loss='deviance',
              max_depth=3, max_features=None, max_leaf_nodes=None,
              min_impurity_decrease=0.0, min_impurity_split=None,
              min_samples_leaf=1, min_samples_split=2,
              min_weight_fraction_leaf=0.0, n_estimators=82,
              n_iter_no_change=None, presort='auto', random_state=1024,
              subsample=1.0, tol=0.0001, validation_fraction=0.1,
              verbose=1, warm_start=False), 'estimator__presort': 'auto', 'estimator__loss': 'deviance', 'estimator__min_samples_split': 2, 'estimator__init': None, 'estimator__tol': 0.0001, 'estimator__min_samples_leaf': 1, 'estimator__verbose': 1}
2019-01-13 14:30:03,359 +----+----------+-------------+----------+----------+-----------+
|    |   fold_# |   precision |   recall |       f1 |   jaccard |
|----+----------+-------------+----------+----------+-----------|
|  0 |        1 |    0.648986 | 0.53913  | 0.560248 |  0.453333 |
|  1 |        2 |    0.678363 | 0.561404 | 0.581871 |  0.465185 |
|  2 |        3 |    0.719697 | 0.681818 | 0.684652 |  0.615185 |
|  3 |        4 |    0.731818 | 0.509091 | 0.569268 |  0.481852 |
|  4 |        5 |    0.646281 | 0.570248 | 0.58267  |  0.539136 |
|  5 |        6 |    0.693623 | 0.66087  | 0.663307 |  0.56672  |
|  6 |        7 |    0.611022 | 0.548387 | 0.561277 |  0.493579 |
|  7 |        8 |    0.651087 | 0.530435 | 0.560663 |  0.476732 |
|  8 |        9 |    0.594907 | 0.52381  | 0.536508 |  0.478788 |
|  9 |       10 |    0.786777 | 0.694215 | 0.713784 |  0.627652 |
+----+----------+-------------+----------+----------+-----------+
2019-01-13 14:30:03,360 CV score f1 : Mean - 0.6014248 | Std - 0.0617632 | Min - 0.5365079 | Max - 0.7137845
2019-01-13 14:30:03,361 CV score jaccard : Mean - 0.5198161 | Std - 0.0635703 | Min - 0.4533333 | Max - 0.6276515





