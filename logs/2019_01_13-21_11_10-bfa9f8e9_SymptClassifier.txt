2019-01-13 21:11:10,880 ****************************************************************************************************
2019-01-13 21:11:10,881 Loading dictionaries from /usr/local/lib/python3.5/dist-packages/pymorphy2_dicts/data
2019-01-13 21:11:10,934 format: 2.4, revision: 393442, updated: 2015-01-17T16:03:56.586168
2019-01-13 21:11:11,393 {'input': 'content', 'dtype': <class 'numpy.int64'>, 'tokenizer': None, 'strip_accents': None, 'vocabulary': None, 'preprocessor': None, 'ngram_range': (1, 5), 'binary': False, 'lowercase': True, 'stop_words': {'будет', 'перед', 'чтоб', 'можно', 'моя', 'него', 'этой', 'вам', 'в', 'еще', 'куда', 'ней', 'нас', 'опять', 'сейчас', 'до', 'эту', 'ним', 'тот', 'без', 'тебя', 'под', 'больше', 'были', 'все', 'им', 'была', 'потому', 'тут', 'лучше', 'меня', 'этого', 'будто', 'всю', 'или', 'быть', 'ничего', 'себе', 'если', 'вы', 'хорошо', 'может', 'один', 'нет', 'над', 'он', 'тоже', 'к', 'где', 'ж', 'об', 'она', 'чем', 'себя', 'какая', 'они', 'с', 'нибудь', 'же', 'более', 'его', 'теперь', 'них', 'этом', 'нельзя', 'почти', 'за', 'да', 'по', 'чтобы', 'наконец', 'после', 'как', 'иногда', 'потом', 'про', 'есть', 'ведь', 'том', 'сам', 'раз', 'ее', 'тогда', 'из', 'три', 'мы', 'никогда', 'эти', 'ли', 'при', 'от', 'и', 'свою', 'уж', 'я', 'чего', 'через', 'не', 'для', 'всего', 'здесь', 'во', 'то', 'их', 'совсем', 'тем', 'чуть', 'всегда', 'конечно', 'зачем', 'другой', 'мой', 'даже', 'уже', 'между', 'на', 'там', 'ну', 'разве', 'вдруг', 'нее', 'вас', 'много', 'кто', 'этот', 'бы', 'ни', 'когда', 'такой', 'только', 'а', 'два', 'надо', 'ему', 'ты', 'хоть', 'ей', 'впрочем', 'так', 'всех', 'был', 'какой', 'было', 'что', 'но', 'вот', 'со', 'того', 'мне', 'у', 'о'}, 'encoding': 'utf-8', 'max_df': 1.0, 'analyzer': 'word', 'token_pattern': '(?u)\\b\\w\\w+\\b', 'max_features': None, 'min_df': 1, 'decode_error': 'strict'}
2019-01-13 21:11:11,394 {'input': 'content', 'dtype': <class 'numpy.float64'>, 'tokenizer': None, 'strip_accents': None, 'vocabulary': None, 'preprocessor': None, 'ngram_range': (1, 5), 'binary': False, 'norm': 'l2', 'lowercase': True, 'smooth_idf': True, 'stop_words': None, 'encoding': 'utf-8', 'max_df': 1.0, 'analyzer': 'word', 'sublinear_tf': False, 'use_idf': True, 'max_features': None, 'token_pattern': '(?u)\\b\\w\\w+\\b', 'min_df': 1, 'decode_error': 'strict'}
2019-01-13 21:11:11,439 X_train features: (401, 68466);
2019-01-13 21:11:11,439 sympt_train_labels: (401, 92)
2019-01-13 21:11:11,439 X_test features: (45, 68466);
2019-01-13 21:11:11,439 sympt_test_labels: (45, 92)
2019-01-13 21:11:11,439 {'estimator__fit_intercept': True, 'estimator__random_state': 1024, 'estimator__max_iter': 1000, 'estimator': LogisticRegression(C=1.2755478561043065, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=1000,
          multi_class='ovr', n_jobs=None, penalty='l1', random_state=1024,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False), 'estimator__C': 1.2755478561043065, 'estimator__verbose': 0, 'estimator__multi_class': 'ovr', 'estimator__dual': False, 'estimator__class_weight': None, 'estimator__warm_start': False, 'estimator__solver': 'liblinear', 'n_jobs': -1, 'estimator__n_jobs': None, 'estimator__intercept_scaling': 1, 'estimator__tol': 0.0001, 'estimator__penalty': 'l1'}
2019-01-13 21:12:18,867 ****************************************************************************************************
2019-01-13 21:12:18,868 Loading dictionaries from /usr/local/lib/python3.5/dist-packages/pymorphy2_dicts/data
2019-01-13 21:12:18,919 format: 2.4, revision: 393442, updated: 2015-01-17T16:03:56.586168
2019-01-13 21:12:19,384 {'input': 'content', 'dtype': <class 'numpy.int64'>, 'tokenizer': None, 'strip_accents': None, 'vocabulary': None, 'preprocessor': None, 'ngram_range': (1, 5), 'binary': False, 'lowercase': True, 'stop_words': {'будет', 'перед', 'чтоб', 'можно', 'моя', 'него', 'этой', 'вам', 'в', 'еще', 'куда', 'ней', 'нас', 'опять', 'сейчас', 'до', 'эту', 'ним', 'тот', 'без', 'тебя', 'под', 'больше', 'были', 'все', 'им', 'была', 'потому', 'тут', 'лучше', 'меня', 'этого', 'будто', 'всю', 'или', 'быть', 'ничего', 'себе', 'если', 'вы', 'хорошо', 'может', 'один', 'нет', 'над', 'он', 'тоже', 'к', 'где', 'ж', 'об', 'она', 'чем', 'себя', 'какая', 'они', 'с', 'нибудь', 'же', 'более', 'его', 'теперь', 'них', 'этом', 'нельзя', 'почти', 'за', 'да', 'по', 'чтобы', 'наконец', 'после', 'как', 'иногда', 'потом', 'про', 'есть', 'ведь', 'том', 'сам', 'раз', 'ее', 'тогда', 'из', 'три', 'мы', 'никогда', 'эти', 'ли', 'при', 'от', 'и', 'свою', 'уж', 'я', 'чего', 'через', 'не', 'для', 'всего', 'здесь', 'во', 'то', 'их', 'совсем', 'тем', 'чуть', 'всегда', 'конечно', 'зачем', 'другой', 'мой', 'даже', 'уже', 'между', 'на', 'там', 'ну', 'разве', 'вдруг', 'нее', 'вас', 'много', 'кто', 'этот', 'бы', 'ни', 'когда', 'такой', 'только', 'а', 'два', 'надо', 'ему', 'ты', 'хоть', 'ей', 'впрочем', 'так', 'всех', 'был', 'какой', 'было', 'что', 'но', 'вот', 'со', 'того', 'мне', 'у', 'о'}, 'encoding': 'utf-8', 'max_df': 1.0, 'analyzer': 'word', 'token_pattern': '(?u)\\b\\w\\w+\\b', 'max_features': None, 'min_df': 1, 'decode_error': 'strict'}
2019-01-13 21:12:19,384 {'input': 'content', 'dtype': <class 'numpy.float64'>, 'tokenizer': None, 'strip_accents': None, 'vocabulary': None, 'preprocessor': None, 'ngram_range': (1, 5), 'binary': False, 'norm': 'l2', 'lowercase': True, 'smooth_idf': True, 'stop_words': None, 'encoding': 'utf-8', 'max_df': 1.0, 'analyzer': 'word', 'sublinear_tf': False, 'use_idf': True, 'max_features': None, 'token_pattern': '(?u)\\b\\w\\w+\\b', 'min_df': 1, 'decode_error': 'strict'}
2019-01-13 21:12:19,431 X_train features: (401, 68466);
2019-01-13 21:12:19,431 sympt_train_labels: (401, 92)
2019-01-13 21:12:19,431 X_test features: (45, 68466);
2019-01-13 21:12:19,431 sympt_test_labels: (45, 92)
2019-01-13 21:12:19,432 {'estimator__fit_intercept': True, 'estimator__random_state': 1024, 'estimator__max_iter': 1000, 'estimator': LogisticRegression(C=8.169596147501819, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=1000,
          multi_class='ovr', n_jobs=None, penalty='l1', random_state=1024,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False), 'estimator__C': 8.169596147501819, 'estimator__verbose': 0, 'estimator__multi_class': 'ovr', 'estimator__dual': False, 'estimator__class_weight': None, 'estimator__warm_start': False, 'estimator__solver': 'liblinear', 'n_jobs': -1, 'estimator__n_jobs': None, 'estimator__intercept_scaling': 1, 'estimator__tol': 0.0001, 'estimator__penalty': 'l1'}
2019-01-13 21:13:21,468 ****************************************************************************************************
2019-01-13 21:13:21,469 Loading dictionaries from /usr/local/lib/python3.5/dist-packages/pymorphy2_dicts/data
2019-01-13 21:13:21,519 format: 2.4, revision: 393442, updated: 2015-01-17T16:03:56.586168
2019-01-13 21:13:21,963 {'input': 'content', 'dtype': <class 'numpy.int64'>, 'tokenizer': None, 'strip_accents': None, 'vocabulary': None, 'preprocessor': None, 'ngram_range': (1, 5), 'binary': False, 'lowercase': True, 'stop_words': {'будет', 'перед', 'чтоб', 'можно', 'моя', 'него', 'этой', 'вам', 'в', 'еще', 'куда', 'ней', 'нас', 'опять', 'сейчас', 'до', 'эту', 'ним', 'тот', 'без', 'тебя', 'под', 'больше', 'были', 'все', 'им', 'была', 'потому', 'тут', 'лучше', 'меня', 'этого', 'будто', 'всю', 'или', 'быть', 'ничего', 'себе', 'если', 'вы', 'хорошо', 'может', 'один', 'нет', 'над', 'он', 'тоже', 'к', 'где', 'ж', 'об', 'она', 'чем', 'себя', 'какая', 'они', 'с', 'нибудь', 'же', 'более', 'его', 'теперь', 'них', 'этом', 'нельзя', 'почти', 'за', 'да', 'по', 'чтобы', 'наконец', 'после', 'как', 'иногда', 'потом', 'про', 'есть', 'ведь', 'том', 'сам', 'раз', 'ее', 'тогда', 'из', 'три', 'мы', 'никогда', 'эти', 'ли', 'при', 'от', 'и', 'свою', 'уж', 'я', 'чего', 'через', 'не', 'для', 'всего', 'здесь', 'во', 'то', 'их', 'совсем', 'тем', 'чуть', 'всегда', 'конечно', 'зачем', 'другой', 'мой', 'даже', 'уже', 'между', 'на', 'там', 'ну', 'разве', 'вдруг', 'нее', 'вас', 'много', 'кто', 'этот', 'бы', 'ни', 'когда', 'такой', 'только', 'а', 'два', 'надо', 'ему', 'ты', 'хоть', 'ей', 'впрочем', 'так', 'всех', 'был', 'какой', 'было', 'что', 'но', 'вот', 'со', 'того', 'мне', 'у', 'о'}, 'encoding': 'utf-8', 'max_df': 1.0, 'analyzer': 'word', 'token_pattern': '(?u)\\b\\w\\w+\\b', 'max_features': None, 'min_df': 1, 'decode_error': 'strict'}
2019-01-13 21:13:21,963 {'input': 'content', 'dtype': <class 'numpy.float64'>, 'tokenizer': None, 'strip_accents': None, 'vocabulary': None, 'preprocessor': None, 'ngram_range': (1, 5), 'binary': False, 'norm': 'l2', 'lowercase': True, 'smooth_idf': True, 'stop_words': None, 'encoding': 'utf-8', 'max_df': 1.0, 'analyzer': 'word', 'sublinear_tf': False, 'use_idf': True, 'max_features': None, 'token_pattern': '(?u)\\b\\w\\w+\\b', 'min_df': 1, 'decode_error': 'strict'}
2019-01-13 21:13:22,010 X_train features: (401, 68466);
2019-01-13 21:13:22,010 sympt_train_labels: (401, 92)
2019-01-13 21:13:22,010 X_test features: (45, 68466);
2019-01-13 21:13:22,010 sympt_test_labels: (45, 92)
2019-01-13 21:13:22,011 {'estimator__fit_intercept': True, 'estimator__random_state': 1024, 'estimator__max_iter': 1000, 'estimator': LogisticRegression(C=6.4804353943131625, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=1000,
          multi_class='ovr', n_jobs=None, penalty='l1', random_state=1024,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False), 'estimator__C': 6.4804353943131625, 'estimator__verbose': 0, 'estimator__multi_class': 'ovr', 'estimator__dual': False, 'estimator__class_weight': None, 'estimator__warm_start': False, 'estimator__solver': 'liblinear', 'n_jobs': -1, 'estimator__n_jobs': None, 'estimator__intercept_scaling': 1, 'estimator__tol': 0.0001, 'estimator__penalty': 'l1'}
2019-01-13 21:14:35,029 ****************************************************************************************************
2019-01-13 21:14:35,030 Loading dictionaries from /usr/local/lib/python3.5/dist-packages/pymorphy2_dicts/data
2019-01-13 21:14:35,079 format: 2.4, revision: 393442, updated: 2015-01-17T16:03:56.586168
2019-01-13 21:14:35,523 {'input': 'content', 'dtype': <class 'numpy.int64'>, 'tokenizer': None, 'strip_accents': None, 'vocabulary': None, 'preprocessor': None, 'ngram_range': (1, 5), 'binary': False, 'lowercase': True, 'stop_words': {'будет', 'перед', 'чтоб', 'можно', 'моя', 'него', 'этой', 'вам', 'в', 'еще', 'куда', 'ней', 'нас', 'опять', 'сейчас', 'до', 'эту', 'ним', 'тот', 'без', 'тебя', 'под', 'больше', 'были', 'все', 'им', 'была', 'потому', 'тут', 'лучше', 'меня', 'этого', 'будто', 'всю', 'или', 'быть', 'ничего', 'себе', 'если', 'вы', 'хорошо', 'может', 'один', 'нет', 'над', 'он', 'тоже', 'к', 'где', 'ж', 'об', 'она', 'чем', 'себя', 'какая', 'они', 'с', 'нибудь', 'же', 'более', 'его', 'теперь', 'них', 'этом', 'нельзя', 'почти', 'за', 'да', 'по', 'чтобы', 'наконец', 'после', 'как', 'иногда', 'потом', 'про', 'есть', 'ведь', 'том', 'сам', 'раз', 'ее', 'тогда', 'из', 'три', 'мы', 'никогда', 'эти', 'ли', 'при', 'от', 'и', 'свою', 'уж', 'я', 'чего', 'через', 'не', 'для', 'всего', 'здесь', 'во', 'то', 'их', 'совсем', 'тем', 'чуть', 'всегда', 'конечно', 'зачем', 'другой', 'мой', 'даже', 'уже', 'между', 'на', 'там', 'ну', 'разве', 'вдруг', 'нее', 'вас', 'много', 'кто', 'этот', 'бы', 'ни', 'когда', 'такой', 'только', 'а', 'два', 'надо', 'ему', 'ты', 'хоть', 'ей', 'впрочем', 'так', 'всех', 'был', 'какой', 'было', 'что', 'но', 'вот', 'со', 'того', 'мне', 'у', 'о'}, 'encoding': 'utf-8', 'max_df': 1.0, 'analyzer': 'word', 'token_pattern': '(?u)\\b\\w\\w+\\b', 'max_features': None, 'min_df': 1, 'decode_error': 'strict'}
2019-01-13 21:14:35,523 {'input': 'content', 'dtype': <class 'numpy.float64'>, 'tokenizer': None, 'strip_accents': None, 'vocabulary': None, 'preprocessor': None, 'ngram_range': (1, 5), 'binary': False, 'norm': 'l2', 'lowercase': True, 'smooth_idf': True, 'stop_words': None, 'encoding': 'utf-8', 'max_df': 1.0, 'analyzer': 'word', 'sublinear_tf': False, 'use_idf': True, 'max_features': None, 'token_pattern': '(?u)\\b\\w\\w+\\b', 'min_df': 1, 'decode_error': 'strict'}
2019-01-13 21:14:35,571 X_train features: (401, 68466);
2019-01-13 21:14:35,571 sympt_train_labels: (401, 92)
2019-01-13 21:14:35,571 X_test features: (45, 68466);
2019-01-13 21:14:35,571 sympt_test_labels: (45, 92)
2019-01-13 21:14:35,572 {'estimator__fit_intercept': True, 'estimator__random_state': 1024, 'estimator__max_iter': 1000, 'estimator': LogisticRegression(C=1.7010884939534647, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=1000,
          multi_class='ovr', n_jobs=None, penalty='l1', random_state=1024,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False), 'estimator__C': 1.7010884939534647, 'estimator__verbose': 0, 'estimator__multi_class': 'ovr', 'estimator__dual': False, 'estimator__class_weight': None, 'estimator__warm_start': False, 'estimator__solver': 'liblinear', 'n_jobs': -1, 'estimator__n_jobs': None, 'estimator__intercept_scaling': 1, 'estimator__tol': 0.0001, 'estimator__penalty': 'l1'}
2019-01-13 21:17:55,651 ****************************************************************************************************
2019-01-13 21:17:55,651 Loading dictionaries from /usr/local/lib/python3.5/dist-packages/pymorphy2_dicts/data
2019-01-13 21:17:55,705 format: 2.4, revision: 393442, updated: 2015-01-17T16:03:56.586168
2019-01-13 21:17:56,146 {'input': 'content', 'dtype': <class 'numpy.int64'>, 'tokenizer': None, 'strip_accents': None, 'vocabulary': None, 'preprocessor': None, 'ngram_range': (1, 5), 'binary': False, 'lowercase': True, 'stop_words': {'будет', 'перед', 'чтоб', 'можно', 'моя', 'него', 'этой', 'вам', 'в', 'еще', 'куда', 'ней', 'нас', 'опять', 'сейчас', 'до', 'эту', 'ним', 'тот', 'без', 'тебя', 'под', 'больше', 'были', 'все', 'им', 'была', 'потому', 'тут', 'лучше', 'меня', 'этого', 'будто', 'всю', 'или', 'быть', 'ничего', 'себе', 'если', 'вы', 'хорошо', 'может', 'один', 'нет', 'над', 'он', 'тоже', 'к', 'где', 'ж', 'об', 'она', 'чем', 'себя', 'какая', 'они', 'с', 'нибудь', 'же', 'более', 'его', 'теперь', 'них', 'этом', 'нельзя', 'почти', 'за', 'да', 'по', 'чтобы', 'наконец', 'после', 'как', 'иногда', 'потом', 'про', 'есть', 'ведь', 'том', 'сам', 'раз', 'ее', 'тогда', 'из', 'три', 'мы', 'никогда', 'эти', 'ли', 'при', 'от', 'и', 'свою', 'уж', 'я', 'чего', 'через', 'не', 'для', 'всего', 'здесь', 'во', 'то', 'их', 'совсем', 'тем', 'чуть', 'всегда', 'конечно', 'зачем', 'другой', 'мой', 'даже', 'уже', 'между', 'на', 'там', 'ну', 'разве', 'вдруг', 'нее', 'вас', 'много', 'кто', 'этот', 'бы', 'ни', 'когда', 'такой', 'только', 'а', 'два', 'надо', 'ему', 'ты', 'хоть', 'ей', 'впрочем', 'так', 'всех', 'был', 'какой', 'было', 'что', 'но', 'вот', 'со', 'того', 'мне', 'у', 'о'}, 'encoding': 'utf-8', 'max_df': 1.0, 'analyzer': 'word', 'token_pattern': '(?u)\\b\\w\\w+\\b', 'max_features': None, 'min_df': 1, 'decode_error': 'strict'}
2019-01-13 21:17:56,147 {'input': 'content', 'dtype': <class 'numpy.float64'>, 'tokenizer': None, 'strip_accents': None, 'vocabulary': None, 'preprocessor': None, 'ngram_range': (1, 5), 'binary': False, 'norm': 'l2', 'lowercase': True, 'smooth_idf': True, 'stop_words': None, 'encoding': 'utf-8', 'max_df': 1.0, 'analyzer': 'word', 'sublinear_tf': False, 'use_idf': True, 'max_features': None, 'token_pattern': '(?u)\\b\\w\\w+\\b', 'min_df': 1, 'decode_error': 'strict'}
2019-01-13 21:17:56,193 X_train features: (401, 68466);
2019-01-13 21:17:56,194 sympt_train_labels: (401, 92)
2019-01-13 21:17:56,194 X_test features: (45, 68466);
2019-01-13 21:17:56,194 sympt_test_labels: (45, 92)
2019-01-13 21:17:56,194 {'estimator__fit_intercept': True, 'estimator__random_state': 1024, 'estimator__max_iter': 1000, 'estimator': LogisticRegression(C=7.789161228100912, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=1000,
          multi_class='ovr', n_jobs=None, penalty='l1', random_state=1024,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False), 'estimator__C': 7.789161228100912, 'estimator__verbose': 0, 'estimator__multi_class': 'ovr', 'estimator__dual': False, 'estimator__class_weight': None, 'estimator__warm_start': False, 'estimator__solver': 'liblinear', 'n_jobs': -1, 'estimator__n_jobs': None, 'estimator__intercept_scaling': 1, 'estimator__tol': 0.0001, 'estimator__penalty': 'l1'}
2019-01-13 21:18:45,141 ****************************************************************************************************
2019-01-13 21:18:45,142 Loading dictionaries from /usr/local/lib/python3.5/dist-packages/pymorphy2_dicts/data
2019-01-13 21:18:45,195 format: 2.4, revision: 393442, updated: 2015-01-17T16:03:56.586168
2019-01-13 21:18:45,648 {'input': 'content', 'dtype': <class 'numpy.int64'>, 'tokenizer': None, 'strip_accents': None, 'vocabulary': None, 'preprocessor': None, 'ngram_range': (1, 5), 'binary': False, 'lowercase': True, 'stop_words': {'будет', 'перед', 'чтоб', 'можно', 'моя', 'него', 'этой', 'вам', 'в', 'еще', 'куда', 'ней', 'нас', 'опять', 'сейчас', 'до', 'эту', 'ним', 'тот', 'без', 'тебя', 'под', 'больше', 'были', 'все', 'им', 'была', 'потому', 'тут', 'лучше', 'меня', 'этого', 'будто', 'всю', 'или', 'быть', 'ничего', 'себе', 'если', 'вы', 'хорошо', 'может', 'один', 'нет', 'над', 'он', 'тоже', 'к', 'где', 'ж', 'об', 'она', 'чем', 'себя', 'какая', 'они', 'с', 'нибудь', 'же', 'более', 'его', 'теперь', 'них', 'этом', 'нельзя', 'почти', 'за', 'да', 'по', 'чтобы', 'наконец', 'после', 'как', 'иногда', 'потом', 'про', 'есть', 'ведь', 'том', 'сам', 'раз', 'ее', 'тогда', 'из', 'три', 'мы', 'никогда', 'эти', 'ли', 'при', 'от', 'и', 'свою', 'уж', 'я', 'чего', 'через', 'не', 'для', 'всего', 'здесь', 'во', 'то', 'их', 'совсем', 'тем', 'чуть', 'всегда', 'конечно', 'зачем', 'другой', 'мой', 'даже', 'уже', 'между', 'на', 'там', 'ну', 'разве', 'вдруг', 'нее', 'вас', 'много', 'кто', 'этот', 'бы', 'ни', 'когда', 'такой', 'только', 'а', 'два', 'надо', 'ему', 'ты', 'хоть', 'ей', 'впрочем', 'так', 'всех', 'был', 'какой', 'было', 'что', 'но', 'вот', 'со', 'того', 'мне', 'у', 'о'}, 'encoding': 'utf-8', 'max_df': 1.0, 'analyzer': 'word', 'token_pattern': '(?u)\\b\\w\\w+\\b', 'max_features': None, 'min_df': 1, 'decode_error': 'strict'}
2019-01-13 21:18:45,649 {'input': 'content', 'dtype': <class 'numpy.float64'>, 'tokenizer': None, 'strip_accents': None, 'vocabulary': None, 'preprocessor': None, 'ngram_range': (1, 5), 'binary': False, 'norm': 'l2', 'lowercase': True, 'smooth_idf': True, 'stop_words': None, 'encoding': 'utf-8', 'max_df': 1.0, 'analyzer': 'word', 'sublinear_tf': False, 'use_idf': True, 'max_features': None, 'token_pattern': '(?u)\\b\\w\\w+\\b', 'min_df': 1, 'decode_error': 'strict'}
2019-01-13 21:18:45,698 X_train features: (401, 68466);
2019-01-13 21:18:45,699 sympt_train_labels: (401, 92)
2019-01-13 21:18:45,699 X_test features: (45, 68466);
2019-01-13 21:18:45,699 sympt_test_labels: (45, 92)
2019-01-13 21:18:45,699 {'estimator__fit_intercept': True, 'estimator__random_state': 1024, 'estimator__max_iter': 1000, 'estimator': LogisticRegression(C=1.4690896684628703, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=1000,
          multi_class='ovr', n_jobs=None, penalty='l1', random_state=1024,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False), 'estimator__C': 1.4690896684628703, 'estimator__verbose': 0, 'estimator__multi_class': 'ovr', 'estimator__dual': False, 'estimator__class_weight': None, 'estimator__warm_start': False, 'estimator__solver': 'liblinear', 'n_jobs': -1, 'estimator__n_jobs': None, 'estimator__intercept_scaling': 1, 'estimator__tol': 0.0001, 'estimator__penalty': 'l1'}
2019-01-13 21:19:45,790 ****************************************************************************************************
2019-01-13 21:19:45,790 Loading dictionaries from /usr/local/lib/python3.5/dist-packages/pymorphy2_dicts/data
2019-01-13 21:19:45,837 format: 2.4, revision: 393442, updated: 2015-01-17T16:03:56.586168
2019-01-13 21:19:46,288 {'input': 'content', 'dtype': <class 'numpy.int64'>, 'tokenizer': None, 'strip_accents': None, 'vocabulary': None, 'preprocessor': None, 'ngram_range': (1, 5), 'binary': False, 'lowercase': True, 'stop_words': {'будет', 'перед', 'чтоб', 'можно', 'моя', 'него', 'этой', 'вам', 'в', 'еще', 'куда', 'ней', 'нас', 'опять', 'сейчас', 'до', 'эту', 'ним', 'тот', 'без', 'тебя', 'под', 'больше', 'были', 'все', 'им', 'была', 'потому', 'тут', 'лучше', 'меня', 'этого', 'будто', 'всю', 'или', 'быть', 'ничего', 'себе', 'если', 'вы', 'хорошо', 'может', 'один', 'нет', 'над', 'он', 'тоже', 'к', 'где', 'ж', 'об', 'она', 'чем', 'себя', 'какая', 'они', 'с', 'нибудь', 'же', 'более', 'его', 'теперь', 'них', 'этом', 'нельзя', 'почти', 'за', 'да', 'по', 'чтобы', 'наконец', 'после', 'как', 'иногда', 'потом', 'про', 'есть', 'ведь', 'том', 'сам', 'раз', 'ее', 'тогда', 'из', 'три', 'мы', 'никогда', 'эти', 'ли', 'при', 'от', 'и', 'свою', 'уж', 'я', 'чего', 'через', 'не', 'для', 'всего', 'здесь', 'во', 'то', 'их', 'совсем', 'тем', 'чуть', 'всегда', 'конечно', 'зачем', 'другой', 'мой', 'даже', 'уже', 'между', 'на', 'там', 'ну', 'разве', 'вдруг', 'нее', 'вас', 'много', 'кто', 'этот', 'бы', 'ни', 'когда', 'такой', 'только', 'а', 'два', 'надо', 'ему', 'ты', 'хоть', 'ей', 'впрочем', 'так', 'всех', 'был', 'какой', 'было', 'что', 'но', 'вот', 'со', 'того', 'мне', 'у', 'о'}, 'encoding': 'utf-8', 'max_df': 1.0, 'analyzer': 'word', 'token_pattern': '(?u)\\b\\w\\w+\\b', 'max_features': None, 'min_df': 1, 'decode_error': 'strict'}
2019-01-13 21:19:46,288 {'input': 'content', 'dtype': <class 'numpy.float64'>, 'tokenizer': None, 'strip_accents': None, 'vocabulary': None, 'preprocessor': None, 'ngram_range': (1, 5), 'binary': False, 'norm': 'l2', 'lowercase': True, 'smooth_idf': True, 'stop_words': None, 'encoding': 'utf-8', 'max_df': 1.0, 'analyzer': 'word', 'sublinear_tf': False, 'use_idf': True, 'max_features': None, 'token_pattern': '(?u)\\b\\w\\w+\\b', 'min_df': 1, 'decode_error': 'strict'}
2019-01-13 21:19:46,335 X_train features: (402, 68466);
2019-01-13 21:19:46,335 sympt_train_labels: (402, 92)
2019-01-13 21:19:46,335 X_test features: (44, 68466);
2019-01-13 21:19:46,335 sympt_test_labels: (44, 92)
2019-01-13 21:19:46,336 {'estimator__fit_intercept': True, 'estimator__random_state': 1024, 'estimator__max_iter': 1000, 'estimator': LogisticRegression(C=3.1735796924204944, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=1000,
          multi_class='ovr', n_jobs=None, penalty='l1', random_state=1024,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False), 'estimator__C': 3.1735796924204944, 'estimator__verbose': 0, 'estimator__multi_class': 'ovr', 'estimator__dual': False, 'estimator__class_weight': None, 'estimator__warm_start': False, 'estimator__solver': 'liblinear', 'n_jobs': -1, 'estimator__n_jobs': None, 'estimator__intercept_scaling': 1, 'estimator__tol': 0.0001, 'estimator__penalty': 'l1'}
2019-01-13 21:20:42,703 ****************************************************************************************************
2019-01-13 21:20:42,704 Loading dictionaries from /usr/local/lib/python3.5/dist-packages/pymorphy2_dicts/data
2019-01-13 21:20:42,816 format: 2.4, revision: 393442, updated: 2015-01-17T16:03:56.586168
2019-01-13 21:20:43,264 {'input': 'content', 'dtype': <class 'numpy.int64'>, 'tokenizer': None, 'strip_accents': None, 'vocabulary': None, 'preprocessor': None, 'ngram_range': (1, 5), 'binary': False, 'lowercase': True, 'stop_words': {'будет', 'перед', 'чтоб', 'можно', 'моя', 'него', 'этой', 'вам', 'в', 'еще', 'куда', 'ней', 'нас', 'опять', 'сейчас', 'до', 'эту', 'ним', 'тот', 'без', 'тебя', 'под', 'больше', 'были', 'все', 'им', 'была', 'потому', 'тут', 'лучше', 'меня', 'этого', 'будто', 'всю', 'или', 'быть', 'ничего', 'себе', 'если', 'вы', 'хорошо', 'может', 'один', 'нет', 'над', 'он', 'тоже', 'к', 'где', 'ж', 'об', 'она', 'чем', 'себя', 'какая', 'они', 'с', 'нибудь', 'же', 'более', 'его', 'теперь', 'них', 'этом', 'нельзя', 'почти', 'за', 'да', 'по', 'чтобы', 'наконец', 'после', 'как', 'иногда', 'потом', 'про', 'есть', 'ведь', 'том', 'сам', 'раз', 'ее', 'тогда', 'из', 'три', 'мы', 'никогда', 'эти', 'ли', 'при', 'от', 'и', 'свою', 'уж', 'я', 'чего', 'через', 'не', 'для', 'всего', 'здесь', 'во', 'то', 'их', 'совсем', 'тем', 'чуть', 'всегда', 'конечно', 'зачем', 'другой', 'мой', 'даже', 'уже', 'между', 'на', 'там', 'ну', 'разве', 'вдруг', 'нее', 'вас', 'много', 'кто', 'этот', 'бы', 'ни', 'когда', 'такой', 'только', 'а', 'два', 'надо', 'ему', 'ты', 'хоть', 'ей', 'впрочем', 'так', 'всех', 'был', 'какой', 'было', 'что', 'но', 'вот', 'со', 'того', 'мне', 'у', 'о'}, 'encoding': 'utf-8', 'max_df': 1.0, 'analyzer': 'word', 'token_pattern': '(?u)\\b\\w\\w+\\b', 'max_features': None, 'min_df': 1, 'decode_error': 'strict'}
2019-01-13 21:20:43,264 {'input': 'content', 'dtype': <class 'numpy.float64'>, 'tokenizer': None, 'strip_accents': None, 'vocabulary': None, 'preprocessor': None, 'ngram_range': (1, 5), 'binary': False, 'norm': 'l2', 'lowercase': True, 'smooth_idf': True, 'stop_words': None, 'encoding': 'utf-8', 'max_df': 1.0, 'analyzer': 'word', 'sublinear_tf': False, 'use_idf': True, 'max_features': None, 'token_pattern': '(?u)\\b\\w\\w+\\b', 'min_df': 1, 'decode_error': 'strict'}
2019-01-13 21:20:43,311 X_train features: (402, 68466);
2019-01-13 21:20:43,311 sympt_train_labels: (402, 92)
2019-01-13 21:20:43,311 X_test features: (44, 68466);
2019-01-13 21:20:43,312 sympt_test_labels: (44, 92)
2019-01-13 21:20:43,312 {'estimator__fit_intercept': True, 'estimator__random_state': 1024, 'estimator__max_iter': 1000, 'estimator': LogisticRegression(C=6.4804353943131625, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=1000,
          multi_class='ovr', n_jobs=None, penalty='l1', random_state=1024,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False), 'estimator__C': 6.4804353943131625, 'estimator__verbose': 0, 'estimator__multi_class': 'ovr', 'estimator__dual': False, 'estimator__class_weight': None, 'estimator__warm_start': False, 'estimator__solver': 'liblinear', 'n_jobs': -1, 'estimator__n_jobs': None, 'estimator__intercept_scaling': 1, 'estimator__tol': 0.0001, 'estimator__penalty': 'l1'}
2019-01-13 21:27:44,098 ****************************************************************************************************
2019-01-13 21:27:44,099 Loading dictionaries from /usr/local/lib/python3.5/dist-packages/pymorphy2_dicts/data
2019-01-13 21:27:44,147 format: 2.4, revision: 393442, updated: 2015-01-17T16:03:56.586168
2019-01-13 21:27:44,617 {'input': 'content', 'dtype': <class 'numpy.int64'>, 'tokenizer': None, 'strip_accents': None, 'vocabulary': None, 'preprocessor': None, 'ngram_range': (1, 5), 'binary': False, 'lowercase': True, 'stop_words': {'будет', 'перед', 'чтоб', 'можно', 'моя', 'него', 'этой', 'вам', 'в', 'еще', 'куда', 'ней', 'нас', 'опять', 'сейчас', 'до', 'эту', 'ним', 'тот', 'без', 'тебя', 'под', 'больше', 'были', 'все', 'им', 'была', 'потому', 'тут', 'лучше', 'меня', 'этого', 'будто', 'всю', 'или', 'быть', 'ничего', 'себе', 'если', 'вы', 'хорошо', 'может', 'один', 'нет', 'над', 'он', 'тоже', 'к', 'где', 'ж', 'об', 'она', 'чем', 'себя', 'какая', 'они', 'с', 'нибудь', 'же', 'более', 'его', 'теперь', 'них', 'этом', 'нельзя', 'почти', 'за', 'да', 'по', 'чтобы', 'наконец', 'после', 'как', 'иногда', 'потом', 'про', 'есть', 'ведь', 'том', 'сам', 'раз', 'ее', 'тогда', 'из', 'три', 'мы', 'никогда', 'эти', 'ли', 'при', 'от', 'и', 'свою', 'уж', 'я', 'чего', 'через', 'не', 'для', 'всего', 'здесь', 'во', 'то', 'их', 'совсем', 'тем', 'чуть', 'всегда', 'конечно', 'зачем', 'другой', 'мой', 'даже', 'уже', 'между', 'на', 'там', 'ну', 'разве', 'вдруг', 'нее', 'вас', 'много', 'кто', 'этот', 'бы', 'ни', 'когда', 'такой', 'только', 'а', 'два', 'надо', 'ему', 'ты', 'хоть', 'ей', 'впрочем', 'так', 'всех', 'был', 'какой', 'было', 'что', 'но', 'вот', 'со', 'того', 'мне', 'у', 'о'}, 'encoding': 'utf-8', 'max_df': 1.0, 'analyzer': 'word', 'token_pattern': '(?u)\\b\\w\\w+\\b', 'max_features': None, 'min_df': 1, 'decode_error': 'strict'}
2019-01-13 21:27:44,618 {'input': 'content', 'dtype': <class 'numpy.float64'>, 'tokenizer': None, 'strip_accents': None, 'vocabulary': None, 'preprocessor': None, 'ngram_range': (1, 5), 'binary': False, 'norm': 'l2', 'lowercase': True, 'smooth_idf': True, 'stop_words': None, 'encoding': 'utf-8', 'max_df': 1.0, 'analyzer': 'word', 'sublinear_tf': False, 'use_idf': True, 'max_features': None, 'token_pattern': '(?u)\\b\\w\\w+\\b', 'min_df': 1, 'decode_error': 'strict'}
2019-01-13 21:27:44,665 X_train features: (402, 68466);
2019-01-13 21:27:44,665 sympt_train_labels: (402, 92)
2019-01-13 21:27:44,665 X_test features: (44, 68466);
2019-01-13 21:27:44,665 sympt_test_labels: (44, 92)
2019-01-13 21:27:44,665 {'estimator__fit_intercept': True, 'estimator__random_state': 1024, 'estimator__max_iter': 1000, 'estimator': LogisticRegression(C=5.994644084225208, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=1000,
          multi_class='ovr', n_jobs=None, penalty='l1', random_state=1024,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False), 'estimator__C': 5.994644084225208, 'estimator__verbose': 0, 'estimator__multi_class': 'ovr', 'estimator__dual': False, 'estimator__class_weight': None, 'estimator__warm_start': False, 'estimator__solver': 'liblinear', 'n_jobs': -1, 'estimator__n_jobs': None, 'estimator__intercept_scaling': 1, 'estimator__tol': 0.0001, 'estimator__penalty': 'l1'}
2019-01-13 21:28:40,034 ****************************************************************************************************
2019-01-13 21:28:40,035 Loading dictionaries from /usr/local/lib/python3.5/dist-packages/pymorphy2_dicts/data
2019-01-13 21:28:40,084 format: 2.4, revision: 393442, updated: 2015-01-17T16:03:56.586168
2019-01-13 21:28:40,530 {'input': 'content', 'dtype': <class 'numpy.int64'>, 'tokenizer': None, 'strip_accents': None, 'vocabulary': None, 'preprocessor': None, 'ngram_range': (1, 5), 'binary': False, 'lowercase': True, 'stop_words': {'будет', 'перед', 'чтоб', 'можно', 'моя', 'него', 'этой', 'вам', 'в', 'еще', 'куда', 'ней', 'нас', 'опять', 'сейчас', 'до', 'эту', 'ним', 'тот', 'без', 'тебя', 'под', 'больше', 'были', 'все', 'им', 'была', 'потому', 'тут', 'лучше', 'меня', 'этого', 'будто', 'всю', 'или', 'быть', 'ничего', 'себе', 'если', 'вы', 'хорошо', 'может', 'один', 'нет', 'над', 'он', 'тоже', 'к', 'где', 'ж', 'об', 'она', 'чем', 'себя', 'какая', 'они', 'с', 'нибудь', 'же', 'более', 'его', 'теперь', 'них', 'этом', 'нельзя', 'почти', 'за', 'да', 'по', 'чтобы', 'наконец', 'после', 'как', 'иногда', 'потом', 'про', 'есть', 'ведь', 'том', 'сам', 'раз', 'ее', 'тогда', 'из', 'три', 'мы', 'никогда', 'эти', 'ли', 'при', 'от', 'и', 'свою', 'уж', 'я', 'чего', 'через', 'не', 'для', 'всего', 'здесь', 'во', 'то', 'их', 'совсем', 'тем', 'чуть', 'всегда', 'конечно', 'зачем', 'другой', 'мой', 'даже', 'уже', 'между', 'на', 'там', 'ну', 'разве', 'вдруг', 'нее', 'вас', 'много', 'кто', 'этот', 'бы', 'ни', 'когда', 'такой', 'только', 'а', 'два', 'надо', 'ему', 'ты', 'хоть', 'ей', 'впрочем', 'так', 'всех', 'был', 'какой', 'было', 'что', 'но', 'вот', 'со', 'того', 'мне', 'у', 'о'}, 'encoding': 'utf-8', 'max_df': 1.0, 'analyzer': 'word', 'token_pattern': '(?u)\\b\\w\\w+\\b', 'max_features': None, 'min_df': 1, 'decode_error': 'strict'}
2019-01-13 21:28:40,530 {'input': 'content', 'dtype': <class 'numpy.float64'>, 'tokenizer': None, 'strip_accents': None, 'vocabulary': None, 'preprocessor': None, 'ngram_range': (1, 5), 'binary': False, 'norm': 'l2', 'lowercase': True, 'smooth_idf': True, 'stop_words': None, 'encoding': 'utf-8', 'max_df': 1.0, 'analyzer': 'word', 'sublinear_tf': False, 'use_idf': True, 'max_features': None, 'token_pattern': '(?u)\\b\\w\\w+\\b', 'min_df': 1, 'decode_error': 'strict'}
2019-01-13 21:28:40,579 X_train features: (402, 68466);
2019-01-13 21:28:40,580 sympt_train_labels: (402, 92)
2019-01-13 21:28:40,580 X_test features: (44, 68466);
2019-01-13 21:28:40,580 sympt_test_labels: (44, 92)
2019-01-13 21:28:40,580 {'estimator__fit_intercept': True, 'estimator__random_state': 1024, 'estimator__max_iter': 1000, 'estimator': LogisticRegression(C=7.5166669815795, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=1000,
          multi_class='ovr', n_jobs=None, penalty='l1', random_state=1024,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False), 'estimator__C': 7.5166669815795, 'estimator__verbose': 0, 'estimator__multi_class': 'ovr', 'estimator__dual': False, 'estimator__class_weight': None, 'estimator__warm_start': False, 'estimator__solver': 'liblinear', 'n_jobs': -1, 'estimator__n_jobs': None, 'estimator__intercept_scaling': 1, 'estimator__tol': 0.0001, 'estimator__penalty': 'l1'}
2019-01-13 21:29:40,364 +----+----------+-------------+----------+----------+-----------+
|    |   fold_# |   precision |   recall |       f1 |   jaccard |
|----+----------+-------------+----------+----------+-----------|
|  0 |        1 |    0.607246 | 0.486957 | 0.515818 |  0.444815 |
|  1 |        2 |    0.599415 | 0.482456 | 0.510443 |  0.445926 |
|  2 |        3 |    0.718182 | 0.636364 | 0.659761 |  0.622963 |
|  3 |        4 |    0.609091 | 0.390909 | 0.442532 |  0.344444 |
|  4 |        5 |    0.667631 | 0.53719  | 0.564947 |  0.538765 |
|  5 |        6 |    0.662754 | 0.582609 | 0.602174 |  0.539312 |
|  6 |        7 |    0.613351 | 0.475806 | 0.514135 |  0.454131 |
|  7 |        8 |    0.618841 | 0.504348 | 0.535611 |  0.484307 |
|  8 |        9 |    0.576389 | 0.492063 | 0.515079 |  0.500379 |
|  9 |       10 |    0.76405  | 0.619835 | 0.663476 |  0.609091 |
+----+----------+-------------+----------+----------+-----------+
2019-01-13 21:29:40,365 CV score f1 : Mean - 0.5523976 | Std - 0.0705593 | Min - 0.4425325 | Max - 0.6634762
2019-01-13 21:29:40,366 CV score jaccard : Mean - 0.4984133 | Std - 0.0833741 | Min - 0.3444444 | Max - 0.6229630
