2019-01-13 00:04:12,264 ****************************************************************************************************
2019-01-13 00:04:12,745 {'encoding': 'utf-8', 'stop_words': {'да', 'вас', 'почти', 'уже', 'или', 'вот', 'ли', 'есть', 'более', 'два', 'тогда', 'после', 'теперь', 'иногда', 'ни', 'лучше', 'ты', 'куда', 'эти', 'с', 'для', 'их', 'нас', 'того', 'были', 'этом', 'мы', 'чего', 'всех', 'про', 'себе', 'но', 'свою', 'мне', 'уж', 'ведь', 'тебя', 'может', 'сейчас', 'ему', 'можно', 'был', 'когда', 'ж', 'том', 'из', 'без', 'была', 'не', 'так', 'зачем', 'от', 'я', 'на', 'эту', 'в', 'еще', 'тоже', 'чуть', 'какой', 'при', 'его', 'моя', 'тот', 'что', 'они', 'перед', 'ничего', 'будто', 'она', 'он', 'себя', 'им', 'если', 'все', 'впрочем', 'где', 'до', 'бы', 'ней', 'больше', 'о', 'потому', 'потом', 'со', 'у', 'ей', 'нее', 'вдруг', 'надо', 'опять', 'здесь', 'ну', 'этой', 'нибудь', 'за', 'три', 'то', 'них', 'чем', 'всегда', 'кто', 'сам', 'и', 'чтобы', 'нет', 'совсем', 'во', 'вы', 'чтоб', 'же', 'много', 'к', 'раз', 'тут', 'хоть', 'только', 'меня', 'а', 'наконец', 'разве', 'над', 'мой', 'под', 'вам', 'между', 'один', 'по', 'хорошо', 'ее', 'него', 'никогда', 'какая', 'будет', 'там', 'об', 'другой', 'было', 'всего', 'ним', 'как', 'быть', 'нельзя', 'такой', 'конечно', 'через', 'этот', 'всю', 'этого', 'тем', 'даже'}, 'max_df': 1.0, 'vocabulary': None, 'preprocessor': None, 'dtype': <class 'numpy.int64'>, 'binary': False, 'min_df': 1, 'decode_error': 'strict', 'max_features': None, 'lowercase': True, 'ngram_range': (1, 5), 'token_pattern': '(?u)\\b\\w\\w+\\b', 'strip_accents': None, 'analyzer': 'word', 'input': 'content', 'tokenizer': None}
2019-01-13 00:04:12,746 {'encoding': 'utf-8', 'stop_words': None, 'max_df': 1.0, 'smooth_idf': True, 'preprocessor': None, 'tokenizer': None, 'dtype': <class 'numpy.int64'>, 'use_idf': True, 'vocabulary': None, 'binary': False, 'min_df': 1, 'sublinear_tf': False, 'decode_error': 'strict', 'max_features': None, 'lowercase': True, 'ngram_range': (1, 5), 'token_pattern': '(?u)\\b\\w\\w+\\b', 'strip_accents': None, 'analyzer': 'word', 'input': 'content', 'norm': 'l2'}
2019-01-13 00:04:12,796 X_train features: (401, 68466);
2019-01-13 00:04:12,797 sympt_train_labels: (401, 92)
2019-01-13 00:04:12,797 X_test features: (45, 68466);
2019-01-13 00:04:12,797 sympt_test_labels: (45, 92)
2019-01-13 00:04:12,797 {'estimator__criterion': 'friedman_mse', 'estimator__min_samples_leaf': 1, 'estimator': GradientBoostingClassifier(criterion='friedman_mse', init=None,
              learning_rate=0.1, loss='deviance', max_depth=3,
              max_features=None, max_leaf_nodes=None,
              min_impurity_decrease=0.0, min_impurity_split=None,
              min_samples_leaf=1, min_samples_split=2,
              min_weight_fraction_leaf=0.0, n_estimators=50,
              presort='auto', random_state=1024, subsample=1.0, verbose=1,
              warm_start=False), 'estimator__n_estimators': 50, 'estimator__verbose': 1, 'estimator__loss': 'deviance', 'estimator__warm_start': False, 'estimator__subsample': 1.0, 'estimator__max_leaf_nodes': None, 'estimator__min_impurity_decrease': 0.0, 'estimator__max_depth': 3, 'estimator__max_features': None, 'estimator__init': None, 'estimator__min_impurity_split': None, 'estimator__learning_rate': 0.1, 'estimator__min_weight_fraction_leaf': 0.0, 'estimator__random_state': 1024, 'estimator__presort': 'auto', 'estimator__min_samples_split': 2, 'n_jobs': -1}
2019-01-13 01:07:38,616 best_params: {'target': 0.5602484472049689, 'params': {'learning_rate': 0.6191102982996944, 'n_estimators': 82.7147133724529}}
2019-01-13 01:07:38,617 ****************************************************************************************************
2019-01-13 01:07:39,096 {'encoding': 'utf-8', 'stop_words': {'да', 'вас', 'почти', 'уже', 'или', 'вот', 'ли', 'есть', 'более', 'два', 'тогда', 'после', 'теперь', 'иногда', 'ни', 'лучше', 'ты', 'куда', 'эти', 'с', 'для', 'их', 'нас', 'того', 'были', 'этом', 'мы', 'чего', 'всех', 'про', 'себе', 'но', 'свою', 'мне', 'уж', 'ведь', 'тебя', 'может', 'сейчас', 'ему', 'можно', 'был', 'когда', 'ж', 'том', 'из', 'без', 'была', 'не', 'так', 'зачем', 'от', 'я', 'на', 'эту', 'в', 'еще', 'тоже', 'чуть', 'какой', 'при', 'его', 'моя', 'тот', 'что', 'они', 'перед', 'ничего', 'будто', 'она', 'он', 'себя', 'им', 'если', 'все', 'впрочем', 'где', 'до', 'бы', 'ней', 'больше', 'о', 'потому', 'потом', 'со', 'у', 'ей', 'нее', 'вдруг', 'надо', 'опять', 'здесь', 'ну', 'этой', 'нибудь', 'за', 'три', 'то', 'них', 'чем', 'всегда', 'кто', 'сам', 'и', 'чтобы', 'нет', 'совсем', 'во', 'вы', 'чтоб', 'же', 'много', 'к', 'раз', 'тут', 'хоть', 'только', 'меня', 'а', 'наконец', 'разве', 'над', 'мой', 'под', 'вам', 'между', 'один', 'по', 'хорошо', 'ее', 'него', 'никогда', 'какая', 'будет', 'там', 'об', 'другой', 'было', 'всего', 'ним', 'как', 'быть', 'нельзя', 'такой', 'конечно', 'через', 'этот', 'всю', 'этого', 'тем', 'даже'}, 'max_df': 1.0, 'vocabulary': None, 'preprocessor': None, 'dtype': <class 'numpy.int64'>, 'binary': False, 'min_df': 1, 'decode_error': 'strict', 'max_features': None, 'lowercase': True, 'ngram_range': (1, 5), 'token_pattern': '(?u)\\b\\w\\w+\\b', 'strip_accents': None, 'analyzer': 'word', 'input': 'content', 'tokenizer': None}
2019-01-13 01:07:39,097 {'encoding': 'utf-8', 'stop_words': None, 'max_df': 1.0, 'smooth_idf': True, 'preprocessor': None, 'tokenizer': None, 'dtype': <class 'numpy.int64'>, 'use_idf': True, 'vocabulary': None, 'binary': False, 'min_df': 1, 'sublinear_tf': False, 'decode_error': 'strict', 'max_features': None, 'lowercase': True, 'ngram_range': (1, 5), 'token_pattern': '(?u)\\b\\w\\w+\\b', 'strip_accents': None, 'analyzer': 'word', 'input': 'content', 'norm': 'l2'}
2019-01-13 01:07:39,147 X_train features: (401, 68466);
2019-01-13 01:07:39,147 sympt_train_labels: (401, 92)
2019-01-13 01:07:39,147 X_test features: (45, 68466);
2019-01-13 01:07:39,148 sympt_test_labels: (45, 92)
2019-01-13 01:07:39,148 {'estimator__criterion': 'friedman_mse', 'estimator__min_samples_leaf': 1, 'estimator': GradientBoostingClassifier(criterion='friedman_mse', init=None,
              learning_rate=0.1, loss='deviance', max_depth=3,
              max_features=None, max_leaf_nodes=None,
              min_impurity_decrease=0.0, min_impurity_split=None,
              min_samples_leaf=1, min_samples_split=2,
              min_weight_fraction_leaf=0.0, n_estimators=50,
              presort='auto', random_state=1024, subsample=1.0, verbose=1,
              warm_start=False), 'estimator__n_estimators': 50, 'estimator__verbose': 1, 'estimator__loss': 'deviance', 'estimator__warm_start': False, 'estimator__subsample': 1.0, 'estimator__max_leaf_nodes': None, 'estimator__min_impurity_decrease': 0.0, 'estimator__max_depth': 3, 'estimator__max_features': None, 'estimator__init': None, 'estimator__min_impurity_split': None, 'estimator__learning_rate': 0.1, 'estimator__min_weight_fraction_leaf': 0.0, 'estimator__random_state': 1024, 'estimator__presort': 'auto', 'estimator__min_samples_split': 2, 'n_jobs': -1}
2019-01-13 02:09:51,720 best_params: {'target': 0.5818713450292398, 'params': {'learning_rate': 0.5428631012213041, 'n_estimators': 76.06789119991836}}
2019-01-13 02:09:51,721 ****************************************************************************************************
2019-01-13 02:09:52,184 {'encoding': 'utf-8', 'stop_words': {'да', 'вас', 'почти', 'уже', 'или', 'вот', 'ли', 'есть', 'более', 'два', 'тогда', 'после', 'теперь', 'иногда', 'ни', 'лучше', 'ты', 'куда', 'эти', 'с', 'для', 'их', 'нас', 'того', 'были', 'этом', 'мы', 'чего', 'всех', 'про', 'себе', 'но', 'свою', 'мне', 'уж', 'ведь', 'тебя', 'может', 'сейчас', 'ему', 'можно', 'был', 'когда', 'ж', 'том', 'из', 'без', 'была', 'не', 'так', 'зачем', 'от', 'я', 'на', 'эту', 'в', 'еще', 'тоже', 'чуть', 'какой', 'при', 'его', 'моя', 'тот', 'что', 'они', 'перед', 'ничего', 'будто', 'она', 'он', 'себя', 'им', 'если', 'все', 'впрочем', 'где', 'до', 'бы', 'ней', 'больше', 'о', 'потому', 'потом', 'со', 'у', 'ей', 'нее', 'вдруг', 'надо', 'опять', 'здесь', 'ну', 'этой', 'нибудь', 'за', 'три', 'то', 'них', 'чем', 'всегда', 'кто', 'сам', 'и', 'чтобы', 'нет', 'совсем', 'во', 'вы', 'чтоб', 'же', 'много', 'к', 'раз', 'тут', 'хоть', 'только', 'меня', 'а', 'наконец', 'разве', 'над', 'мой', 'под', 'вам', 'между', 'один', 'по', 'хорошо', 'ее', 'него', 'никогда', 'какая', 'будет', 'там', 'об', 'другой', 'было', 'всего', 'ним', 'как', 'быть', 'нельзя', 'такой', 'конечно', 'через', 'этот', 'всю', 'этого', 'тем', 'даже'}, 'max_df': 1.0, 'vocabulary': None, 'preprocessor': None, 'dtype': <class 'numpy.int64'>, 'binary': False, 'min_df': 1, 'decode_error': 'strict', 'max_features': None, 'lowercase': True, 'ngram_range': (1, 5), 'token_pattern': '(?u)\\b\\w\\w+\\b', 'strip_accents': None, 'analyzer': 'word', 'input': 'content', 'tokenizer': None}
2019-01-13 02:09:52,185 {'encoding': 'utf-8', 'stop_words': None, 'max_df': 1.0, 'smooth_idf': True, 'preprocessor': None, 'tokenizer': None, 'dtype': <class 'numpy.int64'>, 'use_idf': True, 'vocabulary': None, 'binary': False, 'min_df': 1, 'sublinear_tf': False, 'decode_error': 'strict', 'max_features': None, 'lowercase': True, 'ngram_range': (1, 5), 'token_pattern': '(?u)\\b\\w\\w+\\b', 'strip_accents': None, 'analyzer': 'word', 'input': 'content', 'norm': 'l2'}
2019-01-13 02:09:52,236 X_train features: (401, 68466);
2019-01-13 02:09:52,236 sympt_train_labels: (401, 92)
2019-01-13 02:09:52,236 X_test features: (45, 68466);
2019-01-13 02:09:52,236 sympt_test_labels: (45, 92)
2019-01-13 02:09:52,237 {'estimator__criterion': 'friedman_mse', 'estimator__min_samples_leaf': 1, 'estimator': GradientBoostingClassifier(criterion='friedman_mse', init=None,
              learning_rate=0.1, loss='deviance', max_depth=3,
              max_features=None, max_leaf_nodes=None,
              min_impurity_decrease=0.0, min_impurity_split=None,
              min_samples_leaf=1, min_samples_split=2,
              min_weight_fraction_leaf=0.0, n_estimators=50,
              presort='auto', random_state=1024, subsample=1.0, verbose=1,
              warm_start=False), 'estimator__n_estimators': 50, 'estimator__verbose': 1, 'estimator__loss': 'deviance', 'estimator__warm_start': False, 'estimator__subsample': 1.0, 'estimator__max_leaf_nodes': None, 'estimator__min_impurity_decrease': 0.0, 'estimator__max_depth': 3, 'estimator__max_features': None, 'estimator__init': None, 'estimator__min_impurity_split': None, 'estimator__learning_rate': 0.1, 'estimator__min_weight_fraction_leaf': 0.0, 'estimator__random_state': 1024, 'estimator__presort': 'auto', 'estimator__min_samples_split': 2, 'n_jobs': -1}
2019-01-13 02:53:18,825 best_params: {'target': 0.6846523173795902, 'params': {'learning_rate': 0.6653066691288793, 'n_estimators': 99.78395059108011}}
2019-01-13 02:53:18,826 ****************************************************************************************************
2019-01-13 02:53:19,298 {'encoding': 'utf-8', 'stop_words': {'да', 'вас', 'почти', 'уже', 'или', 'вот', 'ли', 'есть', 'более', 'два', 'тогда', 'после', 'теперь', 'иногда', 'ни', 'лучше', 'ты', 'куда', 'эти', 'с', 'для', 'их', 'нас', 'того', 'были', 'этом', 'мы', 'чего', 'всех', 'про', 'себе', 'но', 'свою', 'мне', 'уж', 'ведь', 'тебя', 'может', 'сейчас', 'ему', 'можно', 'был', 'когда', 'ж', 'том', 'из', 'без', 'была', 'не', 'так', 'зачем', 'от', 'я', 'на', 'эту', 'в', 'еще', 'тоже', 'чуть', 'какой', 'при', 'его', 'моя', 'тот', 'что', 'они', 'перед', 'ничего', 'будто', 'она', 'он', 'себя', 'им', 'если', 'все', 'впрочем', 'где', 'до', 'бы', 'ней', 'больше', 'о', 'потому', 'потом', 'со', 'у', 'ей', 'нее', 'вдруг', 'надо', 'опять', 'здесь', 'ну', 'этой', 'нибудь', 'за', 'три', 'то', 'них', 'чем', 'всегда', 'кто', 'сам', 'и', 'чтобы', 'нет', 'совсем', 'во', 'вы', 'чтоб', 'же', 'много', 'к', 'раз', 'тут', 'хоть', 'только', 'меня', 'а', 'наконец', 'разве', 'над', 'мой', 'под', 'вам', 'между', 'один', 'по', 'хорошо', 'ее', 'него', 'никогда', 'какая', 'будет', 'там', 'об', 'другой', 'было', 'всего', 'ним', 'как', 'быть', 'нельзя', 'такой', 'конечно', 'через', 'этот', 'всю', 'этого', 'тем', 'даже'}, 'max_df': 1.0, 'vocabulary': None, 'preprocessor': None, 'dtype': <class 'numpy.int64'>, 'binary': False, 'min_df': 1, 'decode_error': 'strict', 'max_features': None, 'lowercase': True, 'ngram_range': (1, 5), 'token_pattern': '(?u)\\b\\w\\w+\\b', 'strip_accents': None, 'analyzer': 'word', 'input': 'content', 'tokenizer': None}
2019-01-13 02:53:19,299 {'encoding': 'utf-8', 'stop_words': None, 'max_df': 1.0, 'smooth_idf': True, 'preprocessor': None, 'tokenizer': None, 'dtype': <class 'numpy.int64'>, 'use_idf': True, 'vocabulary': None, 'binary': False, 'min_df': 1, 'sublinear_tf': False, 'decode_error': 'strict', 'max_features': None, 'lowercase': True, 'ngram_range': (1, 5), 'token_pattern': '(?u)\\b\\w\\w+\\b', 'strip_accents': None, 'analyzer': 'word', 'input': 'content', 'norm': 'l2'}
2019-01-13 02:53:19,348 X_train features: (401, 68466);
2019-01-13 02:53:19,348 sympt_train_labels: (401, 92)
2019-01-13 02:53:19,348 X_test features: (45, 68466);
2019-01-13 02:53:19,348 sympt_test_labels: (45, 92)
2019-01-13 02:53:19,349 {'estimator__criterion': 'friedman_mse', 'estimator__min_samples_leaf': 1, 'estimator': GradientBoostingClassifier(criterion='friedman_mse', init=None,
              learning_rate=0.1, loss='deviance', max_depth=3,
              max_features=None, max_leaf_nodes=None,
              min_impurity_decrease=0.0, min_impurity_split=None,
              min_samples_leaf=1, min_samples_split=2,
              min_weight_fraction_leaf=0.0, n_estimators=50,
              presort='auto', random_state=1024, subsample=1.0, verbose=1,
              warm_start=False), 'estimator__n_estimators': 50, 'estimator__verbose': 1, 'estimator__loss': 'deviance', 'estimator__warm_start': False, 'estimator__subsample': 1.0, 'estimator__max_leaf_nodes': None, 'estimator__min_impurity_decrease': 0.0, 'estimator__max_depth': 3, 'estimator__max_features': None, 'estimator__init': None, 'estimator__min_impurity_split': None, 'estimator__learning_rate': 0.1, 'estimator__min_weight_fraction_leaf': 0.0, 'estimator__random_state': 1024, 'estimator__presort': 'auto', 'estimator__min_samples_split': 2, 'n_jobs': -1}
2019-01-13 03:58:57,168 best_params: {'target': 0.5692680047225501, 'params': {'learning_rate': 0.05, 'n_estimators': 59.924674067187325}}
2019-01-13 03:58:57,169 ****************************************************************************************************
2019-01-13 03:58:57,634 {'encoding': 'utf-8', 'stop_words': {'да', 'вас', 'почти', 'уже', 'или', 'вот', 'ли', 'есть', 'более', 'два', 'тогда', 'после', 'теперь', 'иногда', 'ни', 'лучше', 'ты', 'куда', 'эти', 'с', 'для', 'их', 'нас', 'того', 'были', 'этом', 'мы', 'чего', 'всех', 'про', 'себе', 'но', 'свою', 'мне', 'уж', 'ведь', 'тебя', 'может', 'сейчас', 'ему', 'можно', 'был', 'когда', 'ж', 'том', 'из', 'без', 'была', 'не', 'так', 'зачем', 'от', 'я', 'на', 'эту', 'в', 'еще', 'тоже', 'чуть', 'какой', 'при', 'его', 'моя', 'тот', 'что', 'они', 'перед', 'ничего', 'будто', 'она', 'он', 'себя', 'им', 'если', 'все', 'впрочем', 'где', 'до', 'бы', 'ней', 'больше', 'о', 'потому', 'потом', 'со', 'у', 'ей', 'нее', 'вдруг', 'надо', 'опять', 'здесь', 'ну', 'этой', 'нибудь', 'за', 'три', 'то', 'них', 'чем', 'всегда', 'кто', 'сам', 'и', 'чтобы', 'нет', 'совсем', 'во', 'вы', 'чтоб', 'же', 'много', 'к', 'раз', 'тут', 'хоть', 'только', 'меня', 'а', 'наконец', 'разве', 'над', 'мой', 'под', 'вам', 'между', 'один', 'по', 'хорошо', 'ее', 'него', 'никогда', 'какая', 'будет', 'там', 'об', 'другой', 'было', 'всего', 'ним', 'как', 'быть', 'нельзя', 'такой', 'конечно', 'через', 'этот', 'всю', 'этого', 'тем', 'даже'}, 'max_df': 1.0, 'vocabulary': None, 'preprocessor': None, 'dtype': <class 'numpy.int64'>, 'binary': False, 'min_df': 1, 'decode_error': 'strict', 'max_features': None, 'lowercase': True, 'ngram_range': (1, 5), 'token_pattern': '(?u)\\b\\w\\w+\\b', 'strip_accents': None, 'analyzer': 'word', 'input': 'content', 'tokenizer': None}
2019-01-13 03:58:57,635 {'encoding': 'utf-8', 'stop_words': None, 'max_df': 1.0, 'smooth_idf': True, 'preprocessor': None, 'tokenizer': None, 'dtype': <class 'numpy.int64'>, 'use_idf': True, 'vocabulary': None, 'binary': False, 'min_df': 1, 'sublinear_tf': False, 'decode_error': 'strict', 'max_features': None, 'lowercase': True, 'ngram_range': (1, 5), 'token_pattern': '(?u)\\b\\w\\w+\\b', 'strip_accents': None, 'analyzer': 'word', 'input': 'content', 'norm': 'l2'}
2019-01-13 03:58:57,686 X_train features: (401, 68466);
2019-01-13 03:58:57,686 sympt_train_labels: (401, 92)
2019-01-13 03:58:57,686 X_test features: (45, 68466);
2019-01-13 03:58:57,686 sympt_test_labels: (45, 92)
2019-01-13 03:58:57,687 {'estimator__criterion': 'friedman_mse', 'estimator__min_samples_leaf': 1, 'estimator': GradientBoostingClassifier(criterion='friedman_mse', init=None,
              learning_rate=0.1, loss='deviance', max_depth=3,
              max_features=None, max_leaf_nodes=None,
              min_impurity_decrease=0.0, min_impurity_split=None,
              min_samples_leaf=1, min_samples_split=2,
              min_weight_fraction_leaf=0.0, n_estimators=50,
              presort='auto', random_state=1024, subsample=1.0, verbose=1,
              warm_start=False), 'estimator__n_estimators': 50, 'estimator__verbose': 1, 'estimator__loss': 'deviance', 'estimator__warm_start': False, 'estimator__subsample': 1.0, 'estimator__max_leaf_nodes': None, 'estimator__min_impurity_decrease': 0.0, 'estimator__max_depth': 3, 'estimator__max_features': None, 'estimator__init': None, 'estimator__min_impurity_split': None, 'estimator__learning_rate': 0.1, 'estimator__min_weight_fraction_leaf': 0.0, 'estimator__random_state': 1024, 'estimator__presort': 'auto', 'estimator__min_samples_split': 2, 'n_jobs': -1}
2019-01-13 04:47:52,873 best_params: {'target': 0.5826696719258703, 'params': {'learning_rate': 1.0, 'n_estimators': 49.66821638406218}}
2019-01-13 04:47:52,873 ****************************************************************************************************
2019-01-13 04:47:53,344 {'encoding': 'utf-8', 'stop_words': {'да', 'вас', 'почти', 'уже', 'или', 'вот', 'ли', 'есть', 'более', 'два', 'тогда', 'после', 'теперь', 'иногда', 'ни', 'лучше', 'ты', 'куда', 'эти', 'с', 'для', 'их', 'нас', 'того', 'были', 'этом', 'мы', 'чего', 'всех', 'про', 'себе', 'но', 'свою', 'мне', 'уж', 'ведь', 'тебя', 'может', 'сейчас', 'ему', 'можно', 'был', 'когда', 'ж', 'том', 'из', 'без', 'была', 'не', 'так', 'зачем', 'от', 'я', 'на', 'эту', 'в', 'еще', 'тоже', 'чуть', 'какой', 'при', 'его', 'моя', 'тот', 'что', 'они', 'перед', 'ничего', 'будто', 'она', 'он', 'себя', 'им', 'если', 'все', 'впрочем', 'где', 'до', 'бы', 'ней', 'больше', 'о', 'потому', 'потом', 'со', 'у', 'ей', 'нее', 'вдруг', 'надо', 'опять', 'здесь', 'ну', 'этой', 'нибудь', 'за', 'три', 'то', 'них', 'чем', 'всегда', 'кто', 'сам', 'и', 'чтобы', 'нет', 'совсем', 'во', 'вы', 'чтоб', 'же', 'много', 'к', 'раз', 'тут', 'хоть', 'только', 'меня', 'а', 'наконец', 'разве', 'над', 'мой', 'под', 'вам', 'между', 'один', 'по', 'хорошо', 'ее', 'него', 'никогда', 'какая', 'будет', 'там', 'об', 'другой', 'было', 'всего', 'ним', 'как', 'быть', 'нельзя', 'такой', 'конечно', 'через', 'этот', 'всю', 'этого', 'тем', 'даже'}, 'max_df': 1.0, 'vocabulary': None, 'preprocessor': None, 'dtype': <class 'numpy.int64'>, 'binary': False, 'min_df': 1, 'decode_error': 'strict', 'max_features': None, 'lowercase': True, 'ngram_range': (1, 5), 'token_pattern': '(?u)\\b\\w\\w+\\b', 'strip_accents': None, 'analyzer': 'word', 'input': 'content', 'tokenizer': None}
2019-01-13 04:47:53,344 {'encoding': 'utf-8', 'stop_words': None, 'max_df': 1.0, 'smooth_idf': True, 'preprocessor': None, 'tokenizer': None, 'dtype': <class 'numpy.int64'>, 'use_idf': True, 'vocabulary': None, 'binary': False, 'min_df': 1, 'sublinear_tf': False, 'decode_error': 'strict', 'max_features': None, 'lowercase': True, 'ngram_range': (1, 5), 'token_pattern': '(?u)\\b\\w\\w+\\b', 'strip_accents': None, 'analyzer': 'word', 'input': 'content', 'norm': 'l2'}
2019-01-13 04:47:53,395 X_train features: (401, 68466);
2019-01-13 04:47:53,395 sympt_train_labels: (401, 92)
2019-01-13 04:47:53,395 X_test features: (45, 68466);
2019-01-13 04:47:53,395 sympt_test_labels: (45, 92)
2019-01-13 04:47:53,396 {'estimator__criterion': 'friedman_mse', 'estimator__min_samples_leaf': 1, 'estimator': GradientBoostingClassifier(criterion='friedman_mse', init=None,
              learning_rate=0.1, loss='deviance', max_depth=3,
              max_features=None, max_leaf_nodes=None,
              min_impurity_decrease=0.0, min_impurity_split=None,
              min_samples_leaf=1, min_samples_split=2,
              min_weight_fraction_leaf=0.0, n_estimators=50,
              presort='auto', random_state=1024, subsample=1.0, verbose=1,
              warm_start=False), 'estimator__n_estimators': 50, 'estimator__verbose': 1, 'estimator__loss': 'deviance', 'estimator__warm_start': False, 'estimator__subsample': 1.0, 'estimator__max_leaf_nodes': None, 'estimator__min_impurity_decrease': 0.0, 'estimator__max_depth': 3, 'estimator__max_features': None, 'estimator__init': None, 'estimator__min_impurity_split': None, 'estimator__learning_rate': 0.1, 'estimator__min_weight_fraction_leaf': 0.0, 'estimator__random_state': 1024, 'estimator__presort': 'auto', 'estimator__min_samples_split': 2, 'n_jobs': -1}
2019-01-13 05:51:01,800 best_params: {'target': 0.6633069828722002, 'params': {'learning_rate': 0.6191102982996944, 'n_estimators': 82.7147133724529}}
2019-01-13 05:51:01,800 ****************************************************************************************************
2019-01-13 05:51:02,296 {'encoding': 'utf-8', 'stop_words': {'да', 'вас', 'почти', 'уже', 'или', 'вот', 'ли', 'есть', 'более', 'два', 'тогда', 'после', 'теперь', 'иногда', 'ни', 'лучше', 'ты', 'куда', 'эти', 'с', 'для', 'их', 'нас', 'того', 'были', 'этом', 'мы', 'чего', 'всех', 'про', 'себе', 'но', 'свою', 'мне', 'уж', 'ведь', 'тебя', 'может', 'сейчас', 'ему', 'можно', 'был', 'когда', 'ж', 'том', 'из', 'без', 'была', 'не', 'так', 'зачем', 'от', 'я', 'на', 'эту', 'в', 'еще', 'тоже', 'чуть', 'какой', 'при', 'его', 'моя', 'тот', 'что', 'они', 'перед', 'ничего', 'будто', 'она', 'он', 'себя', 'им', 'если', 'все', 'впрочем', 'где', 'до', 'бы', 'ней', 'больше', 'о', 'потому', 'потом', 'со', 'у', 'ей', 'нее', 'вдруг', 'надо', 'опять', 'здесь', 'ну', 'этой', 'нибудь', 'за', 'три', 'то', 'них', 'чем', 'всегда', 'кто', 'сам', 'и', 'чтобы', 'нет', 'совсем', 'во', 'вы', 'чтоб', 'же', 'много', 'к', 'раз', 'тут', 'хоть', 'только', 'меня', 'а', 'наконец', 'разве', 'над', 'мой', 'под', 'вам', 'между', 'один', 'по', 'хорошо', 'ее', 'него', 'никогда', 'какая', 'будет', 'там', 'об', 'другой', 'было', 'всего', 'ним', 'как', 'быть', 'нельзя', 'такой', 'конечно', 'через', 'этот', 'всю', 'этого', 'тем', 'даже'}, 'max_df': 1.0, 'vocabulary': None, 'preprocessor': None, 'dtype': <class 'numpy.int64'>, 'binary': False, 'min_df': 1, 'decode_error': 'strict', 'max_features': None, 'lowercase': True, 'ngram_range': (1, 5), 'token_pattern': '(?u)\\b\\w\\w+\\b', 'strip_accents': None, 'analyzer': 'word', 'input': 'content', 'tokenizer': None}
2019-01-13 05:51:02,297 {'encoding': 'utf-8', 'stop_words': None, 'max_df': 1.0, 'smooth_idf': True, 'preprocessor': None, 'tokenizer': None, 'dtype': <class 'numpy.int64'>, 'use_idf': True, 'vocabulary': None, 'binary': False, 'min_df': 1, 'sublinear_tf': False, 'decode_error': 'strict', 'max_features': None, 'lowercase': True, 'ngram_range': (1, 5), 'token_pattern': '(?u)\\b\\w\\w+\\b', 'strip_accents': None, 'analyzer': 'word', 'input': 'content', 'norm': 'l2'}
2019-01-13 05:51:02,347 X_train features: (402, 68466);
2019-01-13 05:51:02,347 sympt_train_labels: (402, 92)
2019-01-13 05:51:02,347 X_test features: (44, 68466);
2019-01-13 05:51:02,347 sympt_test_labels: (44, 92)
2019-01-13 05:51:02,348 {'estimator__criterion': 'friedman_mse', 'estimator__min_samples_leaf': 1, 'estimator': GradientBoostingClassifier(criterion='friedman_mse', init=None,
              learning_rate=0.1, loss='deviance', max_depth=3,
              max_features=None, max_leaf_nodes=None,
              min_impurity_decrease=0.0, min_impurity_split=None,
              min_samples_leaf=1, min_samples_split=2,
              min_weight_fraction_leaf=0.0, n_estimators=50,
              presort='auto', random_state=1024, subsample=1.0, verbose=1,
              warm_start=False), 'estimator__n_estimators': 50, 'estimator__verbose': 1, 'estimator__loss': 'deviance', 'estimator__warm_start': False, 'estimator__subsample': 1.0, 'estimator__max_leaf_nodes': None, 'estimator__min_impurity_decrease': 0.0, 'estimator__max_depth': 3, 'estimator__max_features': None, 'estimator__init': None, 'estimator__min_impurity_split': None, 'estimator__learning_rate': 0.1, 'estimator__min_weight_fraction_leaf': 0.0, 'estimator__random_state': 1024, 'estimator__presort': 'auto', 'estimator__min_samples_split': 2, 'n_jobs': -1}
2019-01-13 06:45:15,791 best_params: {'target': 0.5612767687720249, 'params': {'learning_rate': 0.6191102982996944, 'n_estimators': 82.7147133724529}}
2019-01-13 06:45:15,791 ****************************************************************************************************
2019-01-13 06:45:16,238 {'encoding': 'utf-8', 'stop_words': {'да', 'вас', 'почти', 'уже', 'или', 'вот', 'ли', 'есть', 'более', 'два', 'тогда', 'после', 'теперь', 'иногда', 'ни', 'лучше', 'ты', 'куда', 'эти', 'с', 'для', 'их', 'нас', 'того', 'были', 'этом', 'мы', 'чего', 'всех', 'про', 'себе', 'но', 'свою', 'мне', 'уж', 'ведь', 'тебя', 'может', 'сейчас', 'ему', 'можно', 'был', 'когда', 'ж', 'том', 'из', 'без', 'была', 'не', 'так', 'зачем', 'от', 'я', 'на', 'эту', 'в', 'еще', 'тоже', 'чуть', 'какой', 'при', 'его', 'моя', 'тот', 'что', 'они', 'перед', 'ничего', 'будто', 'она', 'он', 'себя', 'им', 'если', 'все', 'впрочем', 'где', 'до', 'бы', 'ней', 'больше', 'о', 'потому', 'потом', 'со', 'у', 'ей', 'нее', 'вдруг', 'надо', 'опять', 'здесь', 'ну', 'этой', 'нибудь', 'за', 'три', 'то', 'них', 'чем', 'всегда', 'кто', 'сам', 'и', 'чтобы', 'нет', 'совсем', 'во', 'вы', 'чтоб', 'же', 'много', 'к', 'раз', 'тут', 'хоть', 'только', 'меня', 'а', 'наконец', 'разве', 'над', 'мой', 'под', 'вам', 'между', 'один', 'по', 'хорошо', 'ее', 'него', 'никогда', 'какая', 'будет', 'там', 'об', 'другой', 'было', 'всего', 'ним', 'как', 'быть', 'нельзя', 'такой', 'конечно', 'через', 'этот', 'всю', 'этого', 'тем', 'даже'}, 'max_df': 1.0, 'vocabulary': None, 'preprocessor': None, 'dtype': <class 'numpy.int64'>, 'binary': False, 'min_df': 1, 'decode_error': 'strict', 'max_features': None, 'lowercase': True, 'ngram_range': (1, 5), 'token_pattern': '(?u)\\b\\w\\w+\\b', 'strip_accents': None, 'analyzer': 'word', 'input': 'content', 'tokenizer': None}
2019-01-13 06:45:16,239 {'encoding': 'utf-8', 'stop_words': None, 'max_df': 1.0, 'smooth_idf': True, 'preprocessor': None, 'tokenizer': None, 'dtype': <class 'numpy.int64'>, 'use_idf': True, 'vocabulary': None, 'binary': False, 'min_df': 1, 'sublinear_tf': False, 'decode_error': 'strict', 'max_features': None, 'lowercase': True, 'ngram_range': (1, 5), 'token_pattern': '(?u)\\b\\w\\w+\\b', 'strip_accents': None, 'analyzer': 'word', 'input': 'content', 'norm': 'l2'}
2019-01-13 06:45:16,288 X_train features: (402, 68466);
2019-01-13 06:45:16,288 sympt_train_labels: (402, 92)
2019-01-13 06:45:16,289 X_test features: (44, 68466);
2019-01-13 06:45:16,289 sympt_test_labels: (44, 92)
2019-01-13 06:45:16,289 {'estimator__criterion': 'friedman_mse', 'estimator__min_samples_leaf': 1, 'estimator': GradientBoostingClassifier(criterion='friedman_mse', init=None,
              learning_rate=0.1, loss='deviance', max_depth=3,
              max_features=None, max_leaf_nodes=None,
              min_impurity_decrease=0.0, min_impurity_split=None,
              min_samples_leaf=1, min_samples_split=2,
              min_weight_fraction_leaf=0.0, n_estimators=50,
              presort='auto', random_state=1024, subsample=1.0, verbose=1,
              warm_start=False), 'estimator__n_estimators': 50, 'estimator__verbose': 1, 'estimator__loss': 'deviance', 'estimator__warm_start': False, 'estimator__subsample': 1.0, 'estimator__max_leaf_nodes': None, 'estimator__min_impurity_decrease': 0.0, 'estimator__max_depth': 3, 'estimator__max_features': None, 'estimator__init': None, 'estimator__min_impurity_split': None, 'estimator__learning_rate': 0.1, 'estimator__min_weight_fraction_leaf': 0.0, 'estimator__random_state': 1024, 'estimator__presort': 'auto', 'estimator__min_samples_split': 2, 'n_jobs': -1}
2019-01-13 08:46:53,948 best_params: {'target': 0.5606625258799173, 'params': {'learning_rate': 0.057476929447565744, 'n_estimators': 99.89311671811146}}
2019-01-13 08:46:53,948 ****************************************************************************************************
2019-01-13 08:46:54,439 {'encoding': 'utf-8', 'stop_words': {'да', 'вас', 'почти', 'уже', 'или', 'вот', 'ли', 'есть', 'более', 'два', 'тогда', 'после', 'теперь', 'иногда', 'ни', 'лучше', 'ты', 'куда', 'эти', 'с', 'для', 'их', 'нас', 'того', 'были', 'этом', 'мы', 'чего', 'всех', 'про', 'себе', 'но', 'свою', 'мне', 'уж', 'ведь', 'тебя', 'может', 'сейчас', 'ему', 'можно', 'был', 'когда', 'ж', 'том', 'из', 'без', 'была', 'не', 'так', 'зачем', 'от', 'я', 'на', 'эту', 'в', 'еще', 'тоже', 'чуть', 'какой', 'при', 'его', 'моя', 'тот', 'что', 'они', 'перед', 'ничего', 'будто', 'она', 'он', 'себя', 'им', 'если', 'все', 'впрочем', 'где', 'до', 'бы', 'ней', 'больше', 'о', 'потому', 'потом', 'со', 'у', 'ей', 'нее', 'вдруг', 'надо', 'опять', 'здесь', 'ну', 'этой', 'нибудь', 'за', 'три', 'то', 'них', 'чем', 'всегда', 'кто', 'сам', 'и', 'чтобы', 'нет', 'совсем', 'во', 'вы', 'чтоб', 'же', 'много', 'к', 'раз', 'тут', 'хоть', 'только', 'меня', 'а', 'наконец', 'разве', 'над', 'мой', 'под', 'вам', 'между', 'один', 'по', 'хорошо', 'ее', 'него', 'никогда', 'какая', 'будет', 'там', 'об', 'другой', 'было', 'всего', 'ним', 'как', 'быть', 'нельзя', 'такой', 'конечно', 'через', 'этот', 'всю', 'этого', 'тем', 'даже'}, 'max_df': 1.0, 'vocabulary': None, 'preprocessor': None, 'dtype': <class 'numpy.int64'>, 'binary': False, 'min_df': 1, 'decode_error': 'strict', 'max_features': None, 'lowercase': True, 'ngram_range': (1, 5), 'token_pattern': '(?u)\\b\\w\\w+\\b', 'strip_accents': None, 'analyzer': 'word', 'input': 'content', 'tokenizer': None}
2019-01-13 08:46:54,439 {'encoding': 'utf-8', 'stop_words': None, 'max_df': 1.0, 'smooth_idf': True, 'preprocessor': None, 'tokenizer': None, 'dtype': <class 'numpy.int64'>, 'use_idf': True, 'vocabulary': None, 'binary': False, 'min_df': 1, 'sublinear_tf': False, 'decode_error': 'strict', 'max_features': None, 'lowercase': True, 'ngram_range': (1, 5), 'token_pattern': '(?u)\\b\\w\\w+\\b', 'strip_accents': None, 'analyzer': 'word', 'input': 'content', 'norm': 'l2'}
2019-01-13 08:46:54,488 X_train features: (402, 68466);
2019-01-13 08:46:54,489 sympt_train_labels: (402, 92)
2019-01-13 08:46:54,489 X_test features: (44, 68466);
2019-01-13 08:46:54,489 sympt_test_labels: (44, 92)
2019-01-13 08:46:54,489 {'estimator__criterion': 'friedman_mse', 'estimator__min_samples_leaf': 1, 'estimator': GradientBoostingClassifier(criterion='friedman_mse', init=None,
              learning_rate=0.1, loss='deviance', max_depth=3,
              max_features=None, max_leaf_nodes=None,
              min_impurity_decrease=0.0, min_impurity_split=None,
              min_samples_leaf=1, min_samples_split=2,
              min_weight_fraction_leaf=0.0, n_estimators=50,
              presort='auto', random_state=1024, subsample=1.0, verbose=1,
              warm_start=False), 'estimator__n_estimators': 50, 'estimator__verbose': 1, 'estimator__loss': 'deviance', 'estimator__warm_start': False, 'estimator__subsample': 1.0, 'estimator__max_leaf_nodes': None, 'estimator__min_impurity_decrease': 0.0, 'estimator__max_depth': 3, 'estimator__max_features': None, 'estimator__init': None, 'estimator__min_impurity_split': None, 'estimator__learning_rate': 0.1, 'estimator__min_weight_fraction_leaf': 0.0, 'estimator__random_state': 1024, 'estimator__presort': 'auto', 'estimator__min_samples_split': 2, 'n_jobs': -1}
2019-01-13 09:44:36,474 best_params: {'target': 0.5365079365079366, 'params': {'learning_rate': 0.6653066691288793, 'n_estimators': 99.78395059108011}}
2019-01-13 09:44:36,475 ****************************************************************************************************
2019-01-13 09:44:36,923 {'encoding': 'utf-8', 'stop_words': {'да', 'вас', 'почти', 'уже', 'или', 'вот', 'ли', 'есть', 'более', 'два', 'тогда', 'после', 'теперь', 'иногда', 'ни', 'лучше', 'ты', 'куда', 'эти', 'с', 'для', 'их', 'нас', 'того', 'были', 'этом', 'мы', 'чего', 'всех', 'про', 'себе', 'но', 'свою', 'мне', 'уж', 'ведь', 'тебя', 'может', 'сейчас', 'ему', 'можно', 'был', 'когда', 'ж', 'том', 'из', 'без', 'была', 'не', 'так', 'зачем', 'от', 'я', 'на', 'эту', 'в', 'еще', 'тоже', 'чуть', 'какой', 'при', 'его', 'моя', 'тот', 'что', 'они', 'перед', 'ничего', 'будто', 'она', 'он', 'себя', 'им', 'если', 'все', 'впрочем', 'где', 'до', 'бы', 'ней', 'больше', 'о', 'потому', 'потом', 'со', 'у', 'ей', 'нее', 'вдруг', 'надо', 'опять', 'здесь', 'ну', 'этой', 'нибудь', 'за', 'три', 'то', 'них', 'чем', 'всегда', 'кто', 'сам', 'и', 'чтобы', 'нет', 'совсем', 'во', 'вы', 'чтоб', 'же', 'много', 'к', 'раз', 'тут', 'хоть', 'только', 'меня', 'а', 'наконец', 'разве', 'над', 'мой', 'под', 'вам', 'между', 'один', 'по', 'хорошо', 'ее', 'него', 'никогда', 'какая', 'будет', 'там', 'об', 'другой', 'было', 'всего', 'ним', 'как', 'быть', 'нельзя', 'такой', 'конечно', 'через', 'этот', 'всю', 'этого', 'тем', 'даже'}, 'max_df': 1.0, 'vocabulary': None, 'preprocessor': None, 'dtype': <class 'numpy.int64'>, 'binary': False, 'min_df': 1, 'decode_error': 'strict', 'max_features': None, 'lowercase': True, 'ngram_range': (1, 5), 'token_pattern': '(?u)\\b\\w\\w+\\b', 'strip_accents': None, 'analyzer': 'word', 'input': 'content', 'tokenizer': None}
2019-01-13 09:44:36,924 {'encoding': 'utf-8', 'stop_words': None, 'max_df': 1.0, 'smooth_idf': True, 'preprocessor': None, 'tokenizer': None, 'dtype': <class 'numpy.int64'>, 'use_idf': True, 'vocabulary': None, 'binary': False, 'min_df': 1, 'sublinear_tf': False, 'decode_error': 'strict', 'max_features': None, 'lowercase': True, 'ngram_range': (1, 5), 'token_pattern': '(?u)\\b\\w\\w+\\b', 'strip_accents': None, 'analyzer': 'word', 'input': 'content', 'norm': 'l2'}
2019-01-13 09:44:36,973 X_train features: (402, 68466);
2019-01-13 09:44:36,973 sympt_train_labels: (402, 92)
2019-01-13 09:44:36,973 X_test features: (44, 68466);
2019-01-13 09:44:36,973 sympt_test_labels: (44, 92)
2019-01-13 09:44:36,974 {'estimator__criterion': 'friedman_mse', 'estimator__min_samples_leaf': 1, 'estimator': GradientBoostingClassifier(criterion='friedman_mse', init=None,
              learning_rate=0.1, loss='deviance', max_depth=3,
              max_features=None, max_leaf_nodes=None,
              min_impurity_decrease=0.0, min_impurity_split=None,
              min_samples_leaf=1, min_samples_split=2,
              min_weight_fraction_leaf=0.0, n_estimators=50,
              presort='auto', random_state=1024, subsample=1.0, verbose=1,
              warm_start=False), 'estimator__n_estimators': 50, 'estimator__verbose': 1, 'estimator__loss': 'deviance', 'estimator__warm_start': False, 'estimator__subsample': 1.0, 'estimator__max_leaf_nodes': None, 'estimator__min_impurity_decrease': 0.0, 'estimator__max_depth': 3, 'estimator__max_features': None, 'estimator__init': None, 'estimator__min_impurity_split': None, 'estimator__learning_rate': 0.1, 'estimator__min_weight_fraction_leaf': 0.0, 'estimator__random_state': 1024, 'estimator__presort': 'auto', 'estimator__min_samples_split': 2, 'n_jobs': -1}
2019-01-13 10:39:27,445 best_params: {'target': 0.7137844611528821, 'params': {'learning_rate': 0.6191102982996944, 'n_estimators': 82.7147133724529}}
2019-01-13 10:39:27,446 []
